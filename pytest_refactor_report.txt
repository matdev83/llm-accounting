============================= test session starts ==============================
platform linux -- Python 3.10.17, pytest-8.3.5, pluggy-1.5.0 -- /usr/local/bin/python
cachedir: .pytest_cache
metadata: {'Python': '3.10.17', 'Platform': 'Linux-6.8.0-x86_64-with-glibc2.39', 'Packages': {'pytest': '8.3.5', 'pluggy': '1.5.0'}, 'Plugins': {'cov': '5.0.0', 'mock': '3.14.0', 'asyncio': '0.23.7', 'Faker': '25.0.0', 'anyio': '4.9.0', 'json-report': '1.5.0', 'metadata': '3.1.1'}}
rootdir: /app
configfile: pytest.ini
testpaths: tests
plugins: cov-5.0.0, mock-3.14.0, asyncio-0.23.7, Faker-25.0.0, anyio-4.9.0, json-report-1.5.0, metadata-3.1.1
asyncio: mode=strict
collecting ... collected 226 items / 1 deselected / 225 selected

tests/accounting/rolling_limits_tests/test_day_rolling_limits.py::TestDayRollingLimits::test_day_rolling_limit_output_tokens
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  0%]
tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py::TestHourRollingLimits::test_hour_rolling_boundary_just_inside
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  0%]
tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py::TestHourRollingLimits::test_hour_rolling_boundary_just_outside
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  1%]
tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py::TestHourRollingLimits::test_no_usage_rolling_limit
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  1%]
tests/accounting/rolling_limits_tests/test_minute_rolling_limits.py::TestMinuteRollingLimits::test_minute_rolling_limit_input_tokens
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  2%]
tests/accounting/rolling_limits_tests/test_mixed_rolling_limits.py::TestMixedRollingLimits::test_mixed_fixed_and_rolling_limits_rolling_exceeded
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  2%]
tests/accounting/rolling_limits_tests/test_mixed_rolling_limits.py::TestMixedRollingLimits::test_multiple_rolling_limits_one_exceeded
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  3%]
tests/accounting/rolling_limits_tests/test_month_rolling_limits.py::TestMonthRollingLimits::test_month_rolling_limit_requests
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  3%]
tests/accounting/rolling_limits_tests/test_second_rolling_limits.py::TestSecondRollingLimits::test_basic_second_rolling_limit_exceed_limit
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  4%]
tests/accounting/rolling_limits_tests/test_second_rolling_limits.py::TestSecondRollingLimits::test_basic_second_rolling_limit_within_limit
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  4%]
tests/accounting/rolling_limits_tests/test_second_rolling_limits.py::TestSecondRollingLimits::test_second_rolling_limit_usage_outside_window
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  4%]
tests/accounting/rolling_limits_tests/test_week_rolling_limits.py::TestWeekRollingLimits::test_week_rolling_limit_cost
-------------------------------- live log call ---------------------------------
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:22)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true (connection_manager.py:38)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all(). (connection_manager.py:48)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created. (connection_manager.py:51)
2023-01-01 00:00:00 [    INFO] llm_accounting.services.quota_service: QuotaService initialized. _denial_cache is empty: True (quota_service.py:24)
2023-01-01 00:00:00 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared (connection_manager.py:146)
FAILED                                                                   [  5%]
tests/accounting/test_account_model_limits.py::test_account_model_requests_per_minute
-------------------------------- live log setup --------------------------------
2025-06-08 17:11:29 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing SQLite backend for db: /tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite (connection_manager.py:22)
2025-06-08 17:11:29 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Creating SQLAlchemy engine for sqlite:////tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite (connection_manager.py:38)
2025-06-08 17:11:29 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: Initializing ON-DISK SQLite database (/tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite): using Alembic migrations. (connection_manager.py:53)
2025-06-08 17:11:29 [    INFO] llm_accounting.backends.sqlite_backend_parts.connection_manager: On-disk database /tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite is new. Running migrations and stamping with head revision. (connection_manager.py:73)
2025-06-08 17:11:29 [    INFO] llm_accounting.db_migrations.migrations: Attempting database migrations for URL: sqlite:////tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite (db_migrations.py:60)
FAILED                                                                   [  5%]
tests/accounting/test_account_model_limits.py::test_account_model_requests_per_day FAILED [  6%]
tests/accounting/test_account_model_limits.py::test_account_model_completion_tokens_per_minute FAILED [  6%]
tests/accounting/test_account_model_limits.py::test_account_model_completion_tokens_per_day FAILED [  7%]
tests/accounting/test_account_model_limits.py::test_account_total_requests_per_minute FAILED [  7%]
tests/accounting/test_comprehensive_limits.py::test_comprehensive_limit_scenarios FAILED [  8%]
tests/accounting/test_global_limits.py::test_global_limit FAILED         [  8%]
tests/accounting/test_model_limits.py::test_model_limit_priority FAILED  [  8%]
tests/accounting/test_multi_dimensional_quota.py::test_global_limit_overrides_user_limit FAILED [  9%]
tests/accounting/test_multi_dimensional_quota.py::test_user_limit_triggered_before_global FAILED [  9%]
tests/accounting/test_multi_dimensional_quota.py::test_model_and_project_limits_first_triggered FAILED [ 10%]
tests/accounting/test_multi_dimensional_quota.py::test_denial_cache_ttl_behavior FAILED [ 10%]
tests/accounting/test_multiple_limit_types.py::test_multiple_limit_types FAILED [ 11%]
tests/accounting/test_rolling_limits.py::TestRollingLimits::test_float_comparison_sanity_check PASSED [ 11%]
tests/accounting/test_rolling_limits.py::TestRollingLimits::test_placeholder PASSED [ 12%]
tests/accounting/test_user_caller_limits.py::test_user_caller_combination FAILED [ 12%]
tests/api_compatibility/test_audit_logger_api.py::TestAuditLoggerAPI::test_audit_logger_api_methods_exist PASSED [ 12%]
tests/api_compatibility/test_audit_logger_api.py::TestAuditLoggerAPI::test_get_entries_delegates_to_backend PASSED [ 13%]
tests/api_compatibility/test_audit_logger_api.py::TestAuditLoggerAPI::test_log_event_delegates_to_backend PASSED [ 13%]
tests/api_compatibility/test_audit_logger_api.py::TestAuditLoggerAPI::test_log_prompt_delegates_to_backend PASSED [ 14%]
tests/api_compatibility/test_audit_logger_api.py::TestAuditLoggerAPI::test_log_response_delegates_to_backend PASSED [ 14%]
tests/api_compatibility/test_llm_accounting_api.py::TestLLMAccountingAPI::test_delete_usage_limit_calls_backend PASSED [ 15%]
tests/api_compatibility/test_llm_accounting_api.py::TestLLMAccountingAPI::test_get_usage_limits_returns_list_of_usage_limit_data_from_backend PASSED [ 15%]
tests/api_compatibility/test_llm_accounting_api.py::TestLLMAccountingAPI::test_llm_accounting_api_methods_and_properties_exist PASSED [ 16%]
tests/api_compatibility/test_llm_accounting_api.py::TestLLMAccountingAPI::test_set_usage_limit_passes_usage_limit_data_to_backend PASSED [ 16%]
tests/backends/postgresql_backend_tests/test_postgresql_audit_log.py::TestPostgreSQLAuditLog::test_get_audit_log_entries_delegates_to_query_executor SKIPPED [ 16%]
tests/backends/postgresql_backend_tests/test_postgresql_audit_log.py::TestPostgreSQLAuditLog::test_initialize_audit_log_schema_method_ensures_connection SKIPPED [ 17%]
tests/backends/postgresql_backend_tests/test_postgresql_audit_log.py::TestPostgreSQLAuditLog::test_initialize_creates_audit_log_table SKIPPED [ 17%]
tests/backends/postgresql_backend_tests/test_postgresql_audit_log.py::TestPostgreSQLAuditLog::test_log_audit_event_delegates_and_manages_transaction SKIPPED [ 18%]
tests/backends/postgresql_backend_tests/test_postgresql_init_and_connection.py::TestPostgreSQLInitAndConnection::test_close_connection SKIPPED [ 18%]
tests/backends/postgresql_backend_tests/test_postgresql_init_and_connection.py::TestPostgreSQLInitAndConnection::test_init_success SKIPPED [ 19%]
tests/backends/postgresql_backend_tests/test_postgresql_init_and_connection.py::TestPostgreSQLInitAndConnection::test_initialize_connection_error SKIPPED [ 19%]
tests/backends/postgresql_backend_tests/test_postgresql_init_and_connection.py::TestPostgreSQLInitAndConnection::test_initialize_success SKIPPED [ 20%]
tests/backends/postgresql_backend_tests/test_postgresql_migrations_cache.py::TestPostgreSQLMigrationsCache::test_existing_db_cache_for_different_connection_string PASSED [ 20%]
tests/backends/postgresql_backend_tests/test_postgresql_migrations_cache.py::TestPostgreSQLMigrationsCache::test_existing_db_cache_missing_runs_migrations PASSED [ 20%]
tests/backends/postgresql_backend_tests/test_postgresql_migrations_cache.py::TestPostgreSQLMigrationsCache::test_existing_db_cache_outdated_runs_migrations PASSED [ 21%]
tests/backends/postgresql_backend_tests/test_postgresql_migrations_cache.py::TestPostgreSQLMigrationsCache::test_existing_db_cache_up_to_date_skips_migrations PASSED [ 21%]
tests/backends/postgresql_backend_tests/test_postgresql_migrations_cache.py::TestPostgreSQLMigrationsCache::test_existing_db_migrated_but_model_table_missing_runs_create_all PASSED [ 22%]
tests/backends/postgresql_backend_tests/test_postgresql_migrations_cache.py::TestPostgreSQLMigrationsCache::test_new_database_creates_schema_stamps_and_caches PASSED [ 22%]
tests/backends/postgresql_backend_tests/test_postgresql_query_delegation.py::TestPostgreSQLQueryDelegation::test_get_model_stats_delegates_to_query_executor SKIPPED [ 23%]
tests/backends/postgresql_backend_tests/test_postgresql_query_delegation.py::TestPostgreSQLQueryDelegation::test_get_period_stats_delegates_to_query_executor SKIPPED [ 23%]
tests/backends/postgresql_backend_tests/test_postgresql_query_execution.py::TestPostgreSQLQueryExecution::test_execute_query_non_select_error SKIPPED [ 24%]
tests/backends/postgresql_backend_tests/test_postgresql_query_execution.py::TestPostgreSQLQueryExecution::test_execute_query_success SKIPPED [ 24%]
tests/backends/postgresql_backend_tests/test_postgresql_quota_accounting.py::TestPostgreSQLQuotaAccounting::test_get_accounting_entries_for_quota_db_error SKIPPED [ 24%]
tests/backends/postgresql_backend_tests/test_postgresql_quota_accounting.py::TestPostgreSQLQuotaAccounting::test_get_accounting_entries_for_quota_invalid_type SKIPPED [ 25%]
tests/backends/postgresql_backend_tests/test_postgresql_quota_accounting.py::TestPostgreSQLQuotaAccounting::test_get_accounting_entries_for_quota_no_data SKIPPED [ 25%]
tests/backends/postgresql_backend_tests/test_postgresql_quota_accounting.py::TestPostgreSQLQuotaAccounting::test_get_accounting_entries_for_quota_success SKIPPED [ 26%]
tests/backends/postgresql_backend_tests/test_postgresql_usage_insertion.py::TestPostgreSQLUsageInsertion::test_insert_usage_success SKIPPED [ 26%]
tests/backends/postgresql_backend_tests/test_postgresql_usage_limits.py::TestPostgreSQLUsageLimits::test_delete_usage_limit_success SKIPPED [ 27%]
tests/backends/postgresql_backend_tests/test_postgresql_usage_limits.py::TestPostgreSQLUsageLimits::test_get_usage_limits_uses_limit_manager_and_returns_usage_limit_data SKIPPED [ 27%]
tests/backends/postgresql_backend_tests/test_postgresql_usage_limits.py::TestPostgreSQLUsageLimits::test_insert_usage_limit_uses_limit_manager_with_usage_limit_data SKIPPED [ 28%]
tests/backends/postgresql_backend_tests/test_postgresql_usage_limits.py::TestPostgreSQLUsageLimits::test_postgresql_specific_get_usage_limit_delegates_to_limit_manager SKIPPED [ 28%]
tests/backends/postgresql_backend_tests/test_postgresql_usage_limits.py::TestPostgreSQLUsageLimits::test_postgresql_specific_set_usage_limit_delegates_to_query_executor SKIPPED [ 28%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_audit_log_table_creation PASSED [ 29%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_log_single_audit_event PASSED [ 29%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_log_audit_event_minimal_fields PASSED [ 30%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_all_audit_logs PASSED [ 30%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_with_date_filters PASSED [ 31%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_with_app_name_filter PASSED [ 31%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_with_user_name_filter PASSED [ 32%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_with_project_filter PASSED [ 32%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_with_log_type_filter PASSED [ 32%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_with_limit PASSED [ 33%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_with_combined_filters PASSED [ 33%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_empty_result PASSED [ 34%]
tests/backends/sqlite_backend_tests/test_sqlite_audit_log.py::TestSQLiteAuditLog::test_get_audit_logs_order_by_timestamp PASSED [ 34%]
tests/backends/sqlite_backend_tests/test_sqlite_init_and_usage.py::test_initialize PASSED [ 35%]
tests/backends/sqlite_backend_tests/test_sqlite_init_and_usage.py::test_insert_usage PASSED [ 35%]
tests/backends/sqlite_backend_tests/test_sqlite_init_and_usage.py::test_insert_usage_with_project PASSED [ 36%]
tests/backends/sqlite_backend_tests/test_sqlite_init_and_usage.py::test_tail_retrieves_project PASSED [ 36%]
tests/backends/sqlite_backend_tests/test_sqlite_init_and_usage.py::test_execute_query_filter_by_project PASSED [ 36%]
tests/backends/sqlite_backend_tests/test_sqlite_migrations_cache.py::TestSQLiteMigrationCache::test_existing_db_cache_missing PASSED [ 37%]
tests/backends/sqlite_backend_tests/test_sqlite_migrations_cache.py::TestSQLiteMigrationCache::test_existing_db_cache_outdated PASSED [ 37%]
tests/backends/sqlite_backend_tests/test_sqlite_migrations_cache.py::TestSQLiteMigrationCache::test_existing_db_cache_up_to_date PASSED [ 38%]
tests/backends/sqlite_backend_tests/test_sqlite_migrations_cache.py::TestSQLiteMigrationCache::test_in_memory_database PASSED [ 38%]
tests/backends/sqlite_backend_tests/test_sqlite_migrations_cache.py::TestSQLiteMigrationCache::test_new_database_creates_schema_stamps_and_caches PASSED [ 39%]
tests/backends/sqlite_backend_tests/test_sqlite_stats_and_purge.py::test_get_period_stats PASSED [ 39%]
tests/backends/sqlite_backend_tests/test_sqlite_stats_and_purge.py::test_get_model_stats PASSED [ 40%]
tests/backends/sqlite_backend_tests/test_sqlite_stats_and_purge.py::test_get_model_rankings PASSED [ 40%]
tests/backends/sqlite_backend_tests/test_sqlite_stats_and_purge.py::test_purge PASSED [ 40%]
tests/backends/sqlite_backend_tests/test_sqlite_stats_and_purge.py::test_purge_empty_database PASSED [ 41%]
tests/backends/sqlite_backend_tests/test_sqlite_usage_limits.py::test_insert_project_scope_limit PASSED [ 41%]
tests/backends/sqlite_backend_tests/test_sqlite_usage_limits.py::test_get_usage_limits_filter_by_project_scope PASSED [ 42%]
tests/backends/sqlite_backend_tests/test_sqlite_usage_limits.py::test_get_accounting_entries_for_quota_with_project_filter PASSED [ 42%]
tests/backends/sqlite_backend_tests/test_sqlite_usage_limits.py::test_insert_and_get_usage_limits PASSED [ 43%]
tests/backends/sqlite_backend_tests/test_sqlite_usage_limits.py::test_get_usage_limits_with_filters PASSED [ 43%]
tests/backends/sqlite_backend_tests/test_sqlite_usage_limits.py::test_delete_usage_limit PASSED [ 44%]
tests/backends/sqlite_backend_tests/test_sqlite_usage_limits.py::test_datetime_precision_and_timezone_handling PASSED [ 44%]
tests/backends/test_base.py::test_backend_interface PASSED               [ 44%]
tests/backends/test_base.py::test_backend_abstract_methods PASSED        [ 45%]
tests/backends/test_csv_backend.py::TestCSVBackendInitialization::test_initialization_default_dir PASSED [ 45%]
tests/backends/test_csv_backend.py::TestCSVBackendInitialization::test_initialization_custom_dir PASSED [ 46%]
tests/backends/test_csv_backend.py::TestCSVBackendInitialization::test_data_dir_creation PASSED [ 46%]
tests/backends/test_csv_backend.py::TestCSVBackendInitialization::test_initialization_existing_files PASSED [ 47%]
tests/backends/test_csv_backend.py::TestCSVPurge::test_purge_clears_data_keeps_headers PASSED [ 47%]
tests/backends/test_csv_backend.py::TestAccountingEntries::test_insert_and_tail_single_entry PASSED [ 48%]
tests/backends/test_csv_backend.py::TestUsageLimits::test_insert_get_delete_usage_limit PASSED [ 48%]
tests/backends/test_csv_backend.py::TestAuditLog::test_insert_get_audit_log_entry PASSED [ 48%]
tests/backends/test_csv_backend.py::TestPeriodStats::test_get_period_stats_aggregation PASSED [ 49%]
tests/backends/test_csv_backend.py::TestFileHandlingAndEdgeCases::test_missing_files_recreated_on_operation PASSED [ 49%]
tests/backends/test_csv_backend.py::test_handling_io_error_on_init_standalone PASSED [ 50%]
tests/backends/test_usage_models.py::test_usage_entry_creation PASSED    [ 50%]
tests/backends/test_usage_models.py::test_usage_stats_creation PASSED    [ 51%]
tests/cli/test_cli_limits_project.py::test_cli_limits_set_project_scope_success PASSED [ 51%]
tests/cli/test_cli_limits_project.py::test_cli_limits_set_project_scope_missing_project_name PASSED [ 52%]
tests/cli/test_cli_limits_project.py::test_cli_limits_list_with_project_filters PASSED [ 52%]
tests/cli/test_cli_limits_project.py::test_cli_limits_delete_project_limit PASSED [ 52%]
tests/cli/test_cli_log_event.py::test_log_event_basic PASSED             [ 53%]
tests/cli/test_cli_log_event.py::test_log_event_persists_data PASSED     [ 53%]
tests/cli/test_cli_log_event.py::test_log_event_with_timestamp PASSED    [ 54%]
tests/cli/test_cli_log_event.py::test_log_event_with_iso_timestamp_and_tz PASSED [ 54%]
tests/cli/test_cli_log_event.py::test_log_event_timestamp_parse_error PASSED [ 55%]
tests/cli/test_cli_purge.py::test_purge_with_confirmation PASSED         [ 55%]
tests/cli/test_cli_purge.py::test_purge_without_confirmation PASSED      [ 56%]
tests/cli/test_cli_purge.py::test_purge_with_yes_flag PASSED             [ 56%]
tests/cli/test_cli_purge.py::test_purge_with_yes_flag_long PASSED        [ 56%]
tests/cli/test_cli_stats.py::test_stats_no_period PASSED                 [ 57%]
tests/cli/test_cli_stats.py::test_stats_periods[period_args0-Daily Stats] PASSED [ 57%]
tests/cli/test_cli_stats.py::test_stats_periods[period_args1-Weekly Stats] PASSED [ 58%]
tests/cli/test_cli_stats.py::test_stats_periods[period_args2-Monthly Stats] PASSED [ 58%]
tests/cli/test_cli_stats.py::test_stats_periods[period_args3-Yearly Stats] PASSED [ 59%]
tests/cli/test_cli_stats.py::test_stats_custom_period PASSED             [ 59%]
tests/cli/test_cli_stats.py::test_custom_db_file_usage PASSED            [ 60%]
tests/cli/test_cli_stats.py::test_default_db_file_usage PASSED           [ 60%]
tests/cli/test_cli_stats.py::test_db_file_validation_error PASSED        [ 60%]
tests/cli/test_cli_stats.py::test_db_file_permission_error PASSED        [ 61%]
tests/cli/test_cli_tail.py::test_tail_default PASSED                     [ 61%]
tests/cli/test_cli_tail.py::test_tail_custom_number PASSED               [ 62%]
tests/cli/test_cli_tail.py::test_tail_empty PASSED                       [ 62%]
tests/cli/test_cli_track.py::test_track_usage PASSED                     [ 63%]
tests/cli/test_cli_track.py::test_track_usage_with_project PASSED        [ 63%]
tests/cli/test_cli_track.py::test_track_usage_with_timestamp PASSED      [ 64%]
tests/cli/test_cli_track.py::test_track_usage_with_caller_name PASSED    [ 64%]
tests/cli/test_cli_track.py::test_track_usage_with_username PASSED       [ 64%]
tests/cli/test_cli_track.py::test_track_usage_with_cached_tokens PASSED  [ 65%]
tests/cli/test_cli_track.py::test_track_usage_with_reasoning_tokens PASSED [ 65%]
tests/cli/test_cli_version.py::test_cli_version PASSED                   [ 66%]
tests/cli/test_select/select/test_aggregation.py::test_select_aggregation PASSED [ 66%]
tests/cli/test_select/select/test_basic_query.py::test_select_basic_query PASSED [ 67%]
tests/cli/test_select/select/test_no_results.py::test_select_no_results PASSED [ 67%]
tests/cli/test_select/select/test_non_select_query.py::test_select_non_select_query PASSED [ 68%]
tests/cli/test_select/select/test_output_formatting.py::test_select_output_formatting PASSED [ 68%]
tests/cli/test_select/select/test_syntax_error.py::test_select_syntax_error PASSED [ 68%]
tests/cli/test_select_project.py::test_select_no_project_filter_displays_project_column PASSED [ 69%]
tests/cli/test_select_project.py::test_select_filter_by_project_name PASSED [ 69%]
tests/cli/test_select_project.py::test_select_filter_by_project_null PASSED [ 70%]
tests/core/test_accounting_purge.py::test_purge PASSED                   [ 70%]
tests/core/test_accounting_stats.py::test_get_period_stats PASSED        [ 71%]
tests/core/test_accounting_stats.py::test_get_model_stats PASSED         [ 71%]
tests/core/test_accounting_stats.py::test_get_model_rankings PASSED      [ 72%]
tests/core/test_accounting_tracking.py::test_track_usage PASSED          [ 72%]
tests/core/test_accounting_tracking.py::test_tail PASSED                 [ 72%]
tests/core/test_accounting_tracking.py::test_tail_empty PASSED           [ 73%]
tests/core/test_accounting_tracking.py::test_tail_default_limit PASSED   [ 73%]
tests/core/test_accounting_tracking.py::test_track_usage_with_caller_and_user PASSED [ 74%]
tests/core/test_accounting_tracking.py::test_tail_with_caller_and_user PASSED [ 74%]
tests/core/test_accounting_validation.py::test_track_usage_empty_model PASSED [ 75%]
tests/core/test_accounting_validation.py::test_track_usage_none_model PASSED [ 75%]
tests/core/test_accounting_validation.py::test_usage_entry_empty_model PASSED [ 76%]
tests/core/test_accounting_validation.py::test_usage_entry_none_model PASSED [ 76%]
tests/core/test_accounting_validation.py::test_track_usage_without_timestamp PASSED [ 76%]
tests/core/test_accounting_validation.py::test_track_usage_with_timestamp PASSED [ 77%]
tests/core/test_accounting_validation.py::test_track_usage_with_token_details PASSED [ 77%]
tests/core/test_accounting_validation.py::test_track_usage_default_token_details PASSED [ 78%]
tests/core/test_output_silence.py::TestOutputSilence::test_audit_logger_silence PASSED [ 78%]
tests/core/test_output_silence.py::TestOutputSilence::test_llm_accounting_context_manager_silence PASSED [ 79%]
tests/core/test_output_silence.py::TestOutputSilence::test_mock_backend_operations_debug_silence PASSED [ 79%]
tests/core/test_output_silence.py::TestOutputSilence::test_quota_service_silence PASSED [ 80%]
tests/core/test_project_quota_service.py::test_project_limit_cost FAILED [ 80%]
tests/core/test_project_quota_service.py::test_project_limit_requests FAILED [ 80%]
tests/core/test_project_quota_service.py::test_project_limit_with_global_limit_cost FAILED [ 81%]
tests/core/test_project_quota_service.py::test_project_limit_with_model_limit FAILED [ 81%]
tests/core/test_project_quota_service.py::test_project_limit_with_no_specific_project_in_request FAILED [ 82%]
tests/core/test_project_quota_service.py::test_limit_message_for_project_scope FAILED [ 82%]
tests/core/test_quota_service.py::test_check_quota_no_limits PASSED      [ 83%]
tests/core/test_quota_service.py::test_check_quota_allowed_single_limit FAILED [ 83%]
tests/core/test_quota_service.py::test_check_quota_denied_single_limit FAILED [ 84%]
tests/core/test_quota_service.py::test_check_quota_multiple_limits_one_exceeded FAILED [ 84%]
tests/core/test_quota_service.py::test_check_quota_different_scopes_in_cache FAILED [ 84%]
tests/core/test_quota_service.py::test_check_quota_token_limits FAILED   [ 85%]
tests/core/test_quota_service.py::test_get_period_start_monthly PASSED   [ 85%]
tests/core/test_quota_service.py::test_get_period_start_daily PASSED     [ 86%]
tests/core/test_quota_service.py::test_get_period_start_hourly PASSED    [ 86%]
tests/core/test_quota_service.py::test_get_period_start_minute PASSED    [ 87%]
tests/core/test_quota_service.py::test_get_period_start_second PASSED    [ 87%]
tests/core/test_quota_service.py::test_get_period_start_weekly PASSED    [ 88%]
tests/core/test_quota_service.py::test_get_period_start_unsupported_interval PASSED [ 88%]
tests/core/test_quota_service.py::test_check_quota_enhanced_no_limits PASSED [ 88%]
tests/core/test_quota_service.py::test_check_quota_enhanced_allowed_single_limit FAILED [ 89%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_single_limit PASSED [ 89%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.SECOND-10-9.0-1.1-2024-01-01T00:00:05Z-2024-01-01T00:00:10Z] PASSED [ 90%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.MINUTE-1-50.0-11.0-2024-01-01T00:00:30Z-2024-01-01T00:01:00Z] PASSED [ 90%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.MINUTE-2-50.0-11.0-2024-01-01T00:00:30Z-2024-01-01T00:02:00Z] PASSED [ 91%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.HOUR-1-50.0-11.0-2024-01-01T00:30:00Z-2024-01-01T01:00:00Z] PASSED [ 91%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.DAY-1-20.0-5.0-2024-01-01T12:00:00Z-2024-01-02T00:00:00Z] PASSED [ 92%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.SECOND_ROLLING-10-9.0-1.1-2024-01-01T00:00:10Z-2024-01-01T00:00:10Z] PASSED [ 92%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.MINUTE_ROLLING-1-50.0-11.0-2024-01-01T00:01:00Z-2024-01-01T00:01:00Z] PASSED [ 92%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.HOUR_ROLLING-1-50.0-11.0-2024-01-01T01:00:00Z-2024-01-01T01:00:00Z] PASSED [ 93%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_various_intervals[TimeInterval.MONTH_ROLLING-1-10.0-1.0-2024-01-15T10:00:00Z-2024-02-01T00:00:00Z] PASSED [ 93%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_fixed_month_retry_after PASSED [ 94%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_rolling_month_retry_after PASSED [ 94%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denied_retry_after_zero_or_negative_becomes_zero PASSED [ 95%]
tests/core/test_quota_service.py::test_check_quota_enhanced_denial_cached PASSED [ 95%]
tests/core/test_quota_service.py::test_check_quota_enhanced_cache_expires PASSED [ 96%]
tests/test_audit_log.py::test_log_prompt PASSED                          [ 96%]
tests/test_audit_log.py::test_log_response PASSED                        [ 96%]
tests/test_audit_log.py::test_log_event_method PASSED                    [ 97%]
tests/test_audit_log.py::test_nullable_fields PASSED                     [ 97%]
tests/test_audit_log.py::test_get_entries PASSED                         [ 98%]
tests/test_migrations.py::test_sqlite_initial_migration_creates_schema PASSED [ 98%]
tests/test_migrations.py::test_sqlite_applies_new_migration_and_preserves_data PASSED [ 99%]
tests/test_migrations.py::test_postgresql_initial_migration_creates_schema SKIPPED [ 99%]
tests/test_migrations.py::test_postgresql_applies_new_migration_and_preserves_data SKIPPED [100%]

=================================== FAILURES ===================================
__________ TestDayRollingLimits.test_day_rolling_limit_output_tokens ___________

self = <test_day_rolling_limits.TestDayRollingLimits testMethod=test_day_rolling_limit_output_tokens>

    def test_day_rolling_limit_output_tokens(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.PROJECT.value,
            project_name="test-project",
            limit_type=LimitType.OUTPUT_TOKENS.value,
            max_value=5000,
            interval_unit=TimeInterval.DAY_ROLLING.value,
            interval_value=1, # 1 day rolling window
        )
        self._add_usage_limit(limit_dto)

        # Usage within the last day
        self._add_accounting_entry(
            timestamp=self.now - timedelta(hours=5),
            project_name="test-project",
            output_tokens=2000
        )
        self._add_accounting_entry(
            timestamp=self.now - timedelta(hours=10),
            project_name="test-project",
            output_tokens=1500
        )
        # Usage outside window
        self._add_accounting_entry(
            timestamp=self.now - timedelta(hours=25),
            project_name="test-project",
            output_tokens=1000
        )
        # Usage for another project
        self._add_accounting_entry(
            timestamp=self.now - timedelta(hours=2),
            project_name="other-project",
            output_tokens=500
        )
>       allowed, message = self.quota_service.check_quota(
            model="test-model", username="test-user", caller_name="test-caller",
            project_name="test-project", input_tokens=0, completion_tokens=1000, cost=0
        )

tests/accounting/rolling_limits_tests/test_day_rolling_limits.py:41:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe843f3340>
limits = [UsageLimitDTO(scope='PROJECT', limit_type='output_tokens', max_value=5000.0, interval_unit='day_rolling', interval_va...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 0, request_cost = 0, request_completion_tokens = 1000
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.address`.
DEBUG:faker.factory:Provider `faker.providers.address` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.automotive`.
DEBUG:faker.factory:Provider `faker.providers.automotive` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.bank`.
DEBUG:faker.factory:Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.barcode`.
DEBUG:faker.factory:Provider `faker.providers.barcode` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.color`.
DEBUG:faker.factory:Provider `faker.providers.color` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.company`.
DEBUG:faker.factory:Provider `faker.providers.company` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.credit_card`.
DEBUG:faker.factory:Provider `faker.providers.credit_card` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.currency`.
DEBUG:faker.factory:Provider `faker.providers.currency` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.date_time`.
DEBUG:faker.factory:Provider `faker.providers.date_time` has been localized to `en_US`.
DEBUG:faker.factory:Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG:faker.factory:Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.geo`.
DEBUG:faker.factory:Provider `faker.providers.geo` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.internet`.
DEBUG:faker.factory:Provider `faker.providers.internet` has been localized to `en_US`.
DEBUG:faker.factory:Provider `faker.providers.isbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.job`.
DEBUG:faker.factory:Provider `faker.providers.job` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.lorem`.
DEBUG:faker.factory:Provider `faker.providers.lorem` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.misc`.
DEBUG:faker.factory:Provider `faker.providers.misc` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.passport`.
DEBUG:faker.factory:Provider `faker.providers.passport` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.person`.
DEBUG:faker.factory:Provider `faker.providers.person` has been localized to `en_US`.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.phone_number`.
DEBUG:faker.factory:Provider `faker.providers.phone_number` has been localized to `en_US`.
DEBUG:faker.factory:Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG:faker.factory:Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG:faker.factory:Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG:faker.factory:Looking for locale `en_US` in provider `faker.providers.ssn`.
DEBUG:faker.factory:Provider `faker.providers.ssn` has been localized to `en_US`.
DEBUG:faker.factory:Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.
------------------------------ Captured log setup ------------------------------
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.address`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.address` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.automotive`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.automotive` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.bank`.
DEBUG    faker.factory:factory.py:86 Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.barcode`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.barcode` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.color`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.color` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.company`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.company` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.credit_card`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.credit_card` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.currency`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.currency` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.date_time`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.date_time` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:106 Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG    faker.factory:factory.py:106 Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.geo`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.geo` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.internet`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.internet` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:106 Provider `faker.providers.isbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.job`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.job` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.lorem`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.lorem` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.misc`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.misc` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.passport`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.passport` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.person`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.person` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.phone_number`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.phone_number` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:106 Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG    faker.factory:factory.py:106 Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG    faker.factory:factory.py:106 Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.
DEBUG    faker.factory:factory.py:76 Looking for locale `en_US` in provider `faker.providers.ssn`.
DEBUG    faker.factory:factory.py:95 Provider `faker.providers.ssn` has been localized to `en_US`.
DEBUG    faker.factory:factory.py:106 Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
_________ TestHourRollingLimits.test_hour_rolling_boundary_just_inside _________

self = <test_hour_rolling_limits.TestHourRollingLimits testMethod=test_hour_rolling_boundary_just_inside>

    def test_hour_rolling_boundary_just_inside(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=1,
            interval_unit=TimeInterval.HOUR_ROLLING.value,
            interval_value=1, # 1 hour rolling window
        )
        self._add_usage_limit(limit_dto)

        # Usage exactly 1 hour - 1 second ago (just inside the window)
        self._add_accounting_entry(timestamp=self.now - timedelta(hours=1) + timedelta(seconds=1))

        # This request should exceed the limit
>       allowed, message = self.quota_service.check_quota(
            model="test-model",
            username="test-user",
            caller_name="test-caller",
            input_tokens=10,
            cost=0.01,
            project_name="test-project",
            completion_tokens=20,
        )

tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py:44:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe8564f100>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=1.0, interval_unit='hour_rolling', interval_value=1, m...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 20
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
________ TestHourRollingLimits.test_hour_rolling_boundary_just_outside _________

self = <test_hour_rolling_limits.TestHourRollingLimits testMethod=test_hour_rolling_boundary_just_outside>

    def test_hour_rolling_boundary_just_outside(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=1,
            interval_unit=TimeInterval.HOUR_ROLLING.value,
            interval_value=1, # 1 hour rolling window
        )
        self._add_usage_limit(limit_dto)

        # Usage exactly 1 hour ago (just outside the window, rolling period is current_time - duration)
        self._add_accounting_entry(timestamp=self.now - timedelta(hours=1))

        # This request should be allowed as the previous one is now outside
>       allowed, message = self.quota_service.check_quota(
            model="test-model",
            username="test-user",
            caller_name="test-caller",
            input_tokens=10,
            cost=0.01,
            project_name="test-project",
            completion_tokens=20,
        )

tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py:73:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe842d60b0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=1.0, interval_unit='hour_rolling', interval_value=1, m...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 20
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
______________ TestHourRollingLimits.test_no_usage_rolling_limit _______________

self = <test_hour_rolling_limits.TestHourRollingLimits testMethod=test_no_usage_rolling_limit>

    def test_no_usage_rolling_limit(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=5,
            interval_unit=TimeInterval.HOUR_ROLLING.value,
            interval_value=1, # 1 hour rolling window
        )
        self._add_usage_limit(limit_dto)

        # No prior usage
>       allowed, message = self.quota_service.check_quota(
            model="test-model",
            username="test-user",
            caller_name="test-caller",
            input_tokens=10,
            cost=0.01,
            project_name="test-project",
            completion_tokens=20,
        )

tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py:18:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe842d6c20>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=5.0, interval_unit='hour_rolling', interval_value=1, m...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 20
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
________ TestMinuteRollingLimits.test_minute_rolling_limit_input_tokens ________

self = <test_minute_rolling_limits.TestMinuteRollingLimits testMethod=test_minute_rolling_limit_input_tokens>

    def test_minute_rolling_limit_input_tokens(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.USER.value, # User-specific limit
            username="test-user",
            limit_type=LimitType.INPUT_TOKENS.value,
            max_value=1000,
            interval_unit=TimeInterval.MINUTE_ROLLING.value,
            interval_value=5, # 5 minutes rolling window
        )
        self._add_usage_limit(limit_dto)

        # Usage within the window
        self._add_accounting_entry(
            timestamp=self.now - timedelta(minutes=1),
            username="test-user",
            input_tokens=300
        )
        self._add_accounting_entry(
            timestamp=self.now - timedelta(minutes=3),
            username="test-user",
            input_tokens=400
        )
        # Usage outside the window for the same user
        self._add_accounting_entry(
            timestamp=self.now - timedelta(minutes=10),
            username="test-user",
            input_tokens=500
        )
        # Usage for a different user (should not count)
        self._add_accounting_entry(
            timestamp=self.now - timedelta(minutes=2),
            username="other-user",
            input_tokens=200
        )

        # Current usage for "test-user" is 300 + 400 = 700 tokens.
        # Requesting 250 tokens. Total = 950. Should be allowed.
>       allowed, message = self.quota_service.check_quota(
            model="test-model",
            username="test-user",
            caller_name="test-caller",
            input_tokens=250, # Requesting 250 tokens
            cost=0.01,
            project_name="test-project",
            completion_tokens=0,
        )

tests/accounting/rolling_limits_tests/test_minute_rolling_limits.py:44:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe842a66e0>
limits = [UsageLimitDTO(scope='USER', limit_type='input_tokens', max_value=1000.0, interval_unit='minute_rolling', interval_val...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 250, request_cost = 0.01, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
_ TestMixedRollingLimits.test_mixed_fixed_and_rolling_limits_rolling_exceeded __

self = <test_mixed_rolling_limits.TestMixedRollingLimits testMethod=test_mixed_fixed_and_rolling_limits_rolling_exceeded>

    def test_mixed_fixed_and_rolling_limits_rolling_exceeded(self):
        # Fixed: 10 requests / day (fixed window)
        limit_fixed_day = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value, max_value=10,
            interval_unit=TimeInterval.DAY.value, interval_value=1
        )
        self._add_usage_limit(limit_fixed_day)

        # Rolling: 3 requests / 1 minute rolling
        limit_rolling_minute = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value, max_value=2, # Stricter to test easily
            interval_unit=TimeInterval.MINUTE_ROLLING.value, interval_value=1
        )
        self._add_usage_limit(limit_rolling_minute)

        # Add 2 requests in the last 30 seconds
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=10))
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=20))
        # Add 1 request 2 hours ago (counts for fixed daily, not for 1-min rolling)
        self._add_accounting_entry(timestamp=self.now - timedelta(hours=2))

        # Current state:
        # Fixed daily: 3 requests (10, 20 secs ago, 2 hrs ago) + 1 current = 4. Limit 10. OK.
        # Rolling minute: 2 requests (10, 20 secs ago) + 1 current = 3. Limit 2. FAIL.

>       allowed, message = self.quota_service.check_quota(
            model="test-model", username="test-user", caller_name="test-caller",
            input_tokens=10, cost=0.01, project_name="test-project"
        )

tests/accounting/rolling_limits_tests/test_mixed_rolling_limits.py:61:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe842d45e0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=10.0, interval_unit='day', interval_value=1, model=Non...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
_______ TestMixedRollingLimits.test_multiple_rolling_limits_one_exceeded _______

self = <test_mixed_rolling_limits.TestMixedRollingLimits testMethod=test_multiple_rolling_limits_one_exceeded>

    def test_multiple_rolling_limits_one_exceeded(self):
        # Global: 5 requests / 10 sec rolling
        limit_global_req = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value, max_value=5,
            interval_unit=TimeInterval.SECOND_ROLLING.value, interval_value=10
        )
        self._add_usage_limit(limit_global_req)

        # User: 100 input tokens / 1 min rolling
        limit_user_tokens = UsageLimitDTO(
            scope=LimitScope.USER.value, username="test-user", limit_type=LimitType.INPUT_TOKENS.value, max_value=100,
            interval_unit=TimeInterval.MINUTE_ROLLING.value, interval_value=1
        )
        self._add_usage_limit(limit_user_tokens)

        # Add 6 requests for "test-user" in the last 5 seconds (violates global requests limit)
        for i in range(6):
            self._add_accounting_entry(timestamp=self.now - timedelta(seconds=i+1), username="test-user", input_tokens=10)

>       allowed, message = self.quota_service.check_quota(
            model="test-model", username="test-user", caller_name="test-caller",
            input_tokens=10, cost=0.01, project_name="test-project" # This is the 7th request effectively for global
        )

tests/accounting/rolling_limits_tests/test_mixed_rolling_limits.py:26:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe84122bc0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=5.0, interval_unit='second_rolling', interval_value=10...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
___________ TestMonthRollingLimits.test_month_rolling_limit_requests ___________

self = <test_month_rolling_limits.TestMonthRollingLimits testMethod=test_month_rolling_limit_requests>

    def test_month_rolling_limit_requests(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=100,
            interval_unit=TimeInterval.MONTH_ROLLING.value,
            interval_value=3, # 3 months rolling window
        )
        self._add_usage_limit(limit_dto)

        # Usage within the last 3 months
        self._add_accounting_entry(timestamp=self.now - timedelta(days=15)) # current month
        self._add_accounting_entry(timestamp=self.now - timedelta(days=45)) # previous month
        self._add_accounting_entry(timestamp=self.now - timedelta(days=75)) # month before previous

        # Simulate a bit more complex history for month rolling
        # Current month: 1 entry
        # M-1: 1 entry
        # M-2: 1 entry
        # M-3: (now - timedelta(days=105)) - this should be outside a 3-month rolling window from self.now
        # Let's adjust self.now slightly to make calculations more predictable for month boundaries
        # For simplicity, assume self.now is mid-month, e.g., April 15th.
        # A 3-month rolling window would mean (April 15, March, February). Jan 15 would be out.
        # self.now - timedelta(days=75) is roughly 2.5 months ago.
        # self.now - timedelta(days=105) is roughly 3.5 months ago.

        # Add one more entry that should be outside the 3-month window
        # To be precise with _get_period_start for MONTH_ROLLING:
        # start_time is current_time.replace(year=final_year, month=final_month, day=1, hour=0, minute=0, second=0, microsecond=0)
        # where final_month is derived from (current_time.year * 12 + (current_time.month - 1) - interval_value)

        # For a 3 month interval_value, if current is April, period_start is Feb 1st.
        # So, entries from Feb 1st, March 1st, April (up to now) count. Jan entries don't.

        # Let current be April 15th.
        # M-0 (April): self.now - timedelta(days=5) -> Counts
        # M-1 (March): self.now - timedelta(days=35) -> Counts
        # M-2 (Feb): self.now - timedelta(days=65) -> Counts
        # M-3 (Jan): self.now - timedelta(days=95) -> Should NOT count for a 3-month rolling period starting Feb 1st

        self.session.query(AccountingEntry).delete() # Clear previous entries for this test
        self.session.commit()

        self._add_accounting_entry(timestamp=self.now - timedelta(days=5))  # Counts (current month)
        self._add_accounting_entry(timestamp=self.now - timedelta(days=35)) # Counts (previous month)
        self._add_accounting_entry(timestamp=self.now - timedelta(days=65)) # Counts (month before previous)
        self._add_accounting_entry(timestamp=self.now - timedelta(days=95)) # Should NOT count

        # Current usage = 3 requests. Max is 100.
>       allowed, message = self.quota_service.check_quota(
            model="test-model", username="test-user", caller_name="test-caller",
            input_tokens=1, cost=0.01, project_name="test-project"
        )

tests/accounting/rolling_limits_tests/test_month_rolling_limits.py:57:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe84120a60>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=100.0, interval_unit='monthly_rolling', interval_value...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 1, request_cost = 0.01, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
_____ TestSecondRollingLimits.test_basic_second_rolling_limit_exceed_limit _____

self = <test_second_rolling_limits.TestSecondRollingLimits testMethod=test_basic_second_rolling_limit_exceed_limit>

    def test_basic_second_rolling_limit_exceed_limit(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=3,
            interval_unit=TimeInterval.SECOND_ROLLING.value,
            interval_value=10, # 10 seconds rolling window
        )
        self._add_usage_limit(limit_dto)

        # Add usage within the last 10 seconds
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=1))
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=3))
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=5)) # This is the 3rd request

>       allowed, message = self.quota_service.check_quota(
            model="test-model",
            username="test-user",
            caller_name="test-caller",
            input_tokens=10, # This would be the 4th request
            cost=0.01,
            project_name="test-project",
            completion_tokens=20,
        )

tests/accounting/rolling_limits_tests/test_second_rolling_limits.py:50:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe841bc2b0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=3.0, interval_unit='second_rolling', interval_value=10...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 20
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
_____ TestSecondRollingLimits.test_basic_second_rolling_limit_within_limit _____

self = <test_second_rolling_limits.TestSecondRollingLimits testMethod=test_basic_second_rolling_limit_within_limit>

    def test_basic_second_rolling_limit_within_limit(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=5,
            interval_unit=TimeInterval.SECOND_ROLLING.value,
            interval_value=10, # 10 seconds rolling window
        )
        self._add_usage_limit(limit_dto)

        # Add usage within the last 10 seconds
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=1))
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=3))
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=5))

>       allowed, message = self.quota_service.check_quota(
            model="test-model",
            username="test-user",
            caller_name="test-caller",
            input_tokens=10,
            cost=0.01,
            project_name="test-project",
            completion_tokens=20,
        )

tests/accounting/rolling_limits_tests/test_second_rolling_limits.py:23:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe8417ded0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=5.0, interval_unit='second_rolling', interval_value=10...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 20
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
____ TestSecondRollingLimits.test_second_rolling_limit_usage_outside_window ____

self = <test_second_rolling_limits.TestSecondRollingLimits testMethod=test_second_rolling_limit_usage_outside_window>

    def test_second_rolling_limit_usage_outside_window(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=2,
            interval_unit=TimeInterval.SECOND_ROLLING.value,
            interval_value=5, # 5 seconds rolling window
        )
        self._add_usage_limit(limit_dto)

        # This usage is outside the 5-second window from `self.now`
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=10))
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=7))

        # This usage is within the window
        self._add_accounting_entry(timestamp=self.now - timedelta(seconds=1))

        # Current request + the one recent entry = 2. Should be allowed.
>       allowed, message = self.quota_service.check_quota(
            model="test-model",
            username="test-user",
            caller_name="test-caller",
            input_tokens=10,
            cost=0.01,
            project_name="test-project",
            completion_tokens=20,
        )

tests/accounting/rolling_limits_tests/test_second_rolling_limits.py:83:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe84128dc0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=2.0, interval_unit='second_rolling', interval_value=5,...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 20
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
______________ TestWeekRollingLimits.test_week_rolling_limit_cost ______________

self = <test_week_rolling_limits.TestWeekRollingLimits testMethod=test_week_rolling_limit_cost>

    def test_week_rolling_limit_cost(self):
        limit_dto = UsageLimitDTO(
            scope=LimitScope.CALLER.value,
            caller_name="test-caller",
            limit_type=LimitType.COST.value,
            max_value=25.00,
            interval_unit=TimeInterval.WEEK_ROLLING.value,
            interval_value=2, # 2 weeks rolling window
        )
        self._add_usage_limit(limit_dto)

        # Usage within the last 2 weeks
        self._add_accounting_entry(timestamp=self.now - timedelta(days=3), caller_name="test-caller", cost=10.0)
        self._add_accounting_entry(timestamp=self.now - timedelta(days=10), caller_name="test-caller", cost=7.50)
        # Usage outside window
        self._add_accounting_entry(timestamp=self.now - timedelta(days=20), caller_name="test-caller", cost=5.0)
        # Usage for another caller
        self._add_accounting_entry(timestamp=self.now - timedelta(days=1), caller_name="other-caller", cost=2.0)

        # Current cost for "test-caller": 10.0 + 7.50 = 17.50
        # Requesting cost of 5.0. Total = 22.50. Should be allowed.
>       allowed, message = self.quota_service.check_quota(
            model="test-model", username="test-user", caller_name="test-caller",
            project_name="test-project", input_tokens=0, completion_tokens=0, cost=5.0
        )

tests/accounting/rolling_limits_tests/test_week_rolling_limits.py:28:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83d96bc0>
limits = [UsageLimitDTO(scope='CALLER', limit_type='cost', max_value=25.0, interval_unit='week_rolling', interval_value=2, mode...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'test-model', request_username = 'test-user'
request_caller_name = 'test-caller', project_name_for_usage_sum = 'test-project'
request_input_tokens = 0, request_cost = 5.0, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
----------------------------- Captured stderr call -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO:llm_accounting.services.quota_service:QuotaService initialized. _denial_cache is empty: True
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
------------------------------ Captured log call -------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: file:memdb_test_rolling_limits?mode=memory&cache=shared
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:///file:memdb_test_rolling_limits?mode=memory&cache=shared&uri=true
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:48 Initializing IN-MEMORY SQLite database (file:memdb_test_rolling_limits?mode=memory&cache=shared): creating schema using Base.metadata.create_all().
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:51 In-memory database (file:memdb_test_rolling_limits?mode=memory&cache=shared) schema created.
INFO     llm_accounting.services.quota_service:quota_service.py:24 QuotaService initialized. _denial_cache is empty: True
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:146 Closing SQLAlchemy connection for file:memdb_test_rolling_limits?mode=memory&cache=shared
____________________ test_account_model_requests_per_minute ____________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe842e4a90>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe842e6f50>

    def test_account_model_requests_per_minute(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        """Test requests per minute limit for a specific account and model."""
        username = "test_user_ab"
        model_name = "model_x"
        caller = "caller_rpm"

        global_limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value,
            max_value=100, interval_unit=TimeInterval.MINUTE.value, interval_value=1
        )
        account_model_limit = UsageLimitDTO(
            scope=LimitScope.USER.value,
            username=username,
            model=model_name,
            limit_type=LimitType.REQUESTS.value,
            max_value=3,
            interval_unit=TimeInterval.MINUTE.value,
            interval_value=1
        )
        sqlite_backend_for_accounting.insert_usage_limit(account_model_limit)
        sqlite_backend_for_accounting.insert_usage_limit(global_limit)
        accounting_instance.quota_service.refresh_limits_cache() # Refresh cache after inserting limits

        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer:
            for i in range(3):
                # Advance time by 1 second for each request to ensure distinct timestamps
                freezer.tick(delta=timedelta(seconds=1)) # Use tick for incremental advancement
>               allowed, reason = accounting_instance.check_quota(
                    model=model_name, username=username, caller_name=caller, input_tokens=10, completion_tokens=10
                )

tests/accounting/test_account_model_limits.py:56:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe84113280>
limits = [UsageLimitDTO(scope='USER', limit_type='requests', max_value=3.0, interval_unit='minute', interval_value=1, model='mo...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 29, 104020, tzinfo=datetime.timezone.utc))]
request_model = 'model_x', request_username = 'test_user_ab'
request_caller_name = 'caller_rpm', project_name_for_usage_sum = None
request_input_tokens = 10, request_cost = 0.0, request_completion_tokens = 10
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing SQLite backend for db: /tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Creating SQLAlchemy engine for sqlite:////tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:Initializing ON-DISK SQLite database (/tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite): using Alembic migrations.
INFO:llm_accounting.backends.sqlite_backend_parts.connection_manager:On-disk database /tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite is new. Running migrations and stamping with head revision.
INFO:llm_accounting.db_migrations.migrations:Attempting database migrations for URL: sqlite:////tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
------------------------------ Captured log setup ------------------------------
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:22 Initializing SQLite backend for db: /tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:38 Creating SQLAlchemy engine for sqlite:////tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:53 Initializing ON-DISK SQLite database (/tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite): using Alembic migrations.
INFO     llm_accounting.backends.sqlite_backend_parts.connection_manager:connection_manager.py:73 On-disk database /tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite is new. Running migrations and stamping with head revision.
INFO     llm_accounting.db_migrations.migrations:db_migrations.py:60 Attempting database migrations for URL: sqlite:////tmp/pytest-of-swebot/pytest-18/test_account_model_requests_pe0/test_accounting.sqlite
_____________________ test_account_model_requests_per_day ______________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe843f3760>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe843f3910>

    def test_account_model_requests_per_day(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        """Test requests per day limit for a specific account and model."""
        username = "test_user_cd"
        model_name = "model_y"
        caller = "caller_rpd"

        global_limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value,
            max_value=100, interval_unit=TimeInterval.DAY.value, interval_value=1
        )
        account_model_limit = UsageLimitDTO(
            scope=LimitScope.USER.value,
            username=username,
            model=model_name,
            limit_type=LimitType.REQUESTS.value,
            max_value=2,
            interval_unit=TimeInterval.DAY.value,
            interval_value=1
        )
        sqlite_backend_for_accounting.insert_usage_limit(account_model_limit)
        sqlite_backend_for_accounting.insert_usage_limit(global_limit)
        accounting_instance.quota_service.refresh_limits_cache() # Refresh cache after inserting limits

        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer:
            # Track 2 requests on the same day, but at different times
            freezer.tick(delta=timedelta(hours=10)) # 10:00 AM on Jan 1st
>           allowed, reason = accounting_instance.check_quota(
                model=model_name, username=username, caller_name=caller, input_tokens=10, completion_tokens=10
            )

tests/accounting/test_account_model_limits.py:115:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe841104c0>
limits = [UsageLimitDTO(scope='USER', limit_type='requests', max_value=2.0, interval_unit='day', interval_value=1, model='model...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 29, 291365, tzinfo=datetime.timezone.utc))]
request_model = 'model_y', request_username = 'test_user_cd'
request_caller_name = 'caller_rpd', project_name_for_usage_sum = None
request_input_tokens = 10, request_cost = 0.0, request_completion_tokens = 10
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
_______________ test_account_model_completion_tokens_per_minute ________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe84723e50>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe8435a5f0>

    def test_account_model_completion_tokens_per_minute(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        """Test completion tokens per minute limit for a specific account and model."""
        username = "test_user_ef"
        model_name = "model_z"
        caller = "caller_ctpm"

        global_limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.OUTPUT_TOKENS.value,
            max_value=5000, interval_unit=TimeInterval.MINUTE.value, interval_value=1
        )
        account_model_limit = UsageLimitDTO(
            scope=LimitScope.USER.value,
            username=username,
            model=model_name,
            limit_type=LimitType.OUTPUT_TOKENS.value,
            max_value=1000,
            interval_unit=TimeInterval.MINUTE.value,
            interval_value=1
        )
        sqlite_backend_for_accounting.insert_usage_limit(account_model_limit)
        sqlite_backend_for_accounting.insert_usage_limit(global_limit)
        accounting_instance.quota_service.refresh_limits_cache() # Refresh cache after inserting limits

        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer:
            # First request: 500 tokens
            freezer.tick(delta=timedelta(seconds=0)) # Start at 00:00:00
>           allowed, reason = accounting_instance.check_quota(
                model=model_name, username=username, caller_name=caller, input_tokens=10, completion_tokens=500
            )

tests/accounting/test_account_model_limits.py:182:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe84121480>
limits = [UsageLimitDTO(scope='USER', limit_type='output_tokens', max_value=1000.0, interval_unit='minute', interval_value=1, m...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 29, 416744, tzinfo=datetime.timezone.utc))]
request_model = 'model_z', request_username = 'test_user_ef'
request_caller_name = 'caller_ctpm', project_name_for_usage_sum = None
request_input_tokens = 10, request_cost = 0.0, request_completion_tokens = 500
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
_________________ test_account_model_completion_tokens_per_day _________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe83deb700>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe83de82e0>

    def test_account_model_completion_tokens_per_day(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        """Test completion tokens per day limit for a specific account and model."""
        username = "test_user_gh"
        model_name = "model_a"
        caller = "caller_ctpd"

        global_limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.OUTPUT_TOKENS.value,
            max_value=5000, interval_unit=TimeInterval.DAY.value, interval_value=1
        )
        account_model_limit = UsageLimitDTO(
            scope=LimitScope.USER.value,
            username=username,
            model=model_name,
            limit_type=LimitType.OUTPUT_TOKENS.value,
            max_value=200,
            interval_unit=TimeInterval.DAY.value,
            interval_value=1
        )
        sqlite_backend_for_accounting.insert_usage_limit(account_model_limit)
        sqlite_backend_for_accounting.insert_usage_limit(global_limit)
        accounting_instance.quota_service.refresh_limits_cache() # Refresh cache after inserting limits

        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer:
            # First request: 150 tokens
            freezer.tick(delta=timedelta(seconds=0)) # Start at 00:00:00
>           allowed, reason = accounting_instance.check_quota(
                model=model_name, username=username, caller_name=caller, input_tokens=10, completion_tokens=150
            )

tests/accounting/test_account_model_limits.py:250:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe841ae920>
limits = [UsageLimitDTO(scope='USER', limit_type='output_tokens', max_value=200.0, interval_unit='day', interval_value=1, model...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 29, 535398, tzinfo=datetime.timezone.utc))]
request_model = 'model_a', request_username = 'test_user_gh'
request_caller_name = 'caller_ctpd', project_name_for_usage_sum = None
request_input_tokens = 10, request_cost = 0.0, request_completion_tokens = 150
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
____________________ test_account_total_requests_per_minute ____________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe84121210>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe84122710>

    def test_account_total_requests_per_minute(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        """Test account-wide total requests per minute, ensuring it sums across models and takes precedence."""
        username = "test_user_account_wide"
        caller = "caller_account_total"

        # Account-wide limit (no model specified)
        account_wide_limit = UsageLimitDTO(
            scope=LimitScope.USER.value,
            username=username,
            model=None,  # Explicitly None for account-wide
            caller_name=None, # Explicitly None for account-wide
            limit_type=LimitType.REQUESTS.value,
            max_value=4,
            interval_unit=TimeInterval.MINUTE.value,
            interval_value=1
        )
        user_model_specific_limit = UsageLimitDTO(
            scope=LimitScope.USER.value, # Could also be MODEL scope if username and model are set
            username=username,
            model="specific_model_q",
            limit_type=LimitType.REQUESTS.value,
            max_value=10, # Higher than the account-wide limit
            interval_unit=TimeInterval.MINUTE.value,
            interval_value=1
        )
        global_limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value,
            max_value=100, interval_unit=TimeInterval.MINUTE.value, interval_value=1
        )
        sqlite_backend_for_accounting.insert_usage_limit(account_wide_limit)
        sqlite_backend_for_accounting.insert_usage_limit(user_model_specific_limit)
        sqlite_backend_for_accounting.insert_usage_limit(global_limit)
        accounting_instance.quota_service.refresh_limits_cache() # Refresh cache after inserting limits

        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer:
            # Track 2 requests for model_a
            for i in range(2):
                freezer.tick(delta=timedelta(seconds=1)) # Incremental tick
>               allowed, reason = accounting_instance.check_quota(
                    model="model_a", username=username, caller_name=caller, input_tokens=10, completion_tokens=10
                )

tests/accounting/test_account_model_limits.py:320:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83dd4af0>
limits = [UsageLimitDTO(scope='USER', limit_type='requests', max_value=4.0, interval_unit='minute', interval_value=1, model=Non...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 29, 657192, tzinfo=datetime.timezone.utc))]
request_model = 'model_a', request_username = 'test_user_account_wide'
request_caller_name = 'caller_account_total', project_name_for_usage_sum = None
request_input_tokens = 10, request_cost = 0.0, request_completion_tokens = 10
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
______________________ test_comprehensive_limit_scenarios ______________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe83c2a110>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe83c29a50>

    @freeze_time("2023-01-01 00:00:00", tz_offset=0)
    def test_comprehensive_limit_scenarios(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        from datetime import timedelta # Ensure timedelta is in scope
        backend = sqlite_backend_for_accounting # alias for convenience

        # 1. Define and Insert Limits
        limits_to_insert = [
            # GL1: Global Daily Requests
            UsageLimitDTO(scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value, max_value=100, interval_unit=TimeInterval.DAY.value, interval_value=1, project_name=None, model=None, username=None, caller_name=None),
            # UM1: Tokens/User-Model/Min
            UsageLimitDTO(scope=LimitScope.USER.value, username="user1", model="gpt-4", limit_type=LimitType.OUTPUT_TOKENS.value, max_value=1000, interval_unit=TimeInterval.MINUTE_ROLLING.value, interval_value=1, project_name=None, caller_name=None),
            # UM2: Calls/User-Model/Min (Increased to avoid hitting before token limit in Scenario 2, original value was 5)
            UsageLimitDTO(scope=LimitScope.USER.value, username="user1", model="gpt-4", limit_type=LimitType.REQUESTS.value, max_value=1000, interval_unit=TimeInterval.MINUTE_ROLLING.value, interval_value=1, project_name=None, caller_name=None),
            # New limit for Scenario 1: Requests/User-Model/Min for a dedicated test user
            UsageLimitDTO(scope=LimitScope.USER.value, username="user_requests_test", model="test-model", limit_type=LimitType.REQUESTS.value, max_value=5, interval_unit=TimeInterval.MINUTE_ROLLING.value, interval_value=1, project_name=None, caller_name=None),
            # UM3: Tokens/User-Model/Day
            UsageLimitDTO(scope=LimitScope.USER.value, username="user1", model="gpt-4", limit_type=LimitType.OUTPUT_TOKENS.value, max_value=10000, interval_unit=TimeInterval.DAY.value, interval_value=1, project_name=None, caller_name=None),
            # UM4: Calls/User-Model/Day
            UsageLimitDTO(scope=LimitScope.USER.value, username="user1", model="gpt-4", limit_type=LimitType.REQUESTS.value, max_value=20, interval_unit=TimeInterval.DAY.value, interval_value=1, project_name=None, caller_name=None),
            # UH1: Cost/User/Hour
            UsageLimitDTO(scope=LimitScope.USER.value, username="user1", limit_type=LimitType.COST.value, max_value=2.00, interval_unit=TimeInterval.HOUR.value, interval_value=1, project_name=None, model=None, caller_name=None),
            # UD1: Cost/User/Day
            UsageLimitDTO(scope=LimitScope.USER.value, username="user1", limit_type=LimitType.COST.value, max_value=10.00, interval_unit=TimeInterval.DAY.value, interval_value=1, project_name=None, model=None, caller_name=None),
            # User2 specific limit
            UsageLimitDTO(scope=LimitScope.USER.value, username="user2", model="gpt-3.5-turbo", limit_type=LimitType.REQUESTS.value, max_value=10, interval_unit=TimeInterval.DAY.value, interval_value=1, project_name=None, caller_name=None),
        ]

        for limit in limits_to_insert:
            backend.insert_usage_limit(limit)

        # 2. Force Refresh Cache
        accounting_instance.quota_service.refresh_limits_cache()

        # --- Scenario 1: User-Model Minute Requests Limit (New dedicated limit) ---
        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer: # Initial time
            # Test the new 'user_requests_test' limit (max_value=5 requests/min)
            for i in range(5): # 5 calls
                current_time = datetime(2023, 1, 1, 0, 0, i, tzinfo=timezone.utc) # Advance time by seconds
                freezer.move_to(current_time) # Move the frozen time
>               allowed, message = make_call_and_track(
                    accounting_instance, "test-model", "user_requests_test", input_tokens=1, completion_tokens=1, cost=0.0001
                )

tests/accounting/test_comprehensive_limits.py:110:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests/accounting/test_comprehensive_limits.py:50: in make_call_and_track
    allowed, message = acc_instance.check_quota(
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe842d51e0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=100.0, interval_unit='day', interval_value=1, model=No... 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)), ...]
request_model = 'test-model', request_username = 'user_requests_test'
request_caller_name = 'test_caller', project_name_for_usage_sum = None
request_input_tokens = 1, request_cost = 0.0001, request_completion_tokens = 1
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
______________________________ test_global_limit _______________________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe841bc040>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe841bead0>

    def test_global_limit(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        with freeze_time("2023-01-01 12:00:00", tz_offset=0) as freezer: # Use as context manager
            # Use the backend directly to add UsageLimitData for setup
            limit_to_set = UsageLimitDTO(
                scope=LimitScope.GLOBAL.value,
                limit_type=LimitType.REQUESTS.value,
                max_value=10,
                interval_unit=TimeInterval.MINUTE.value,
                interval_value=1
            )
            sqlite_backend_for_accounting.insert_usage_limit(limit_to_set)


            # Refresh the cache in QuotaService after inserting limits directly into DB
            accounting_instance.quota_service.refresh_limits_cache()

            # Check and add requests sequentially using accounting_instance
            for i in range(10):
                freezer.tick(delta=timedelta(seconds=1)) # Advance time by 1 second for each iteration
                current_timestamp = datetime.now(timezone.utc) # Define before check_quota
>               allowed, reason = accounting_instance.check_quota(
                    "gpt-4", "user1", "app1", 1000, 0.25
                )

tests/accounting/test_global_limits.py:49:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83c2a980>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=10.0, interval_unit='minute', interval_value=1, model=... 1, 1, 12, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1'
request_caller_name = 'app1', project_name_for_usage_sum = None
request_input_tokens = 1000, request_cost = 0.25, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
INFO  [llm_accounting.db_migrations.migrations_head_check] Current head script revision: ba9718840e75
__________________________ test_model_limit_priority ___________________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe842d5990>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe842d6020>

    def test_model_limit_priority(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        with freeze_time("2023-01-01 10:00:00", tz_offset=0) as freezer:
            # Setting up a global limit directly on the backend using UsageLimitData
            global_limit = UsageLimitDTO(
                scope=LimitScope.GLOBAL.value,
                limit_type=LimitType.REQUESTS.value,
                max_value=100,
                interval_unit=TimeInterval.MINUTE.value,
                interval_value=1
            )
            model_limit = UsageLimitDTO(
                scope=LimitScope.MODEL.value,
                model="gpt-4",
                limit_type=LimitType.REQUESTS.value,
                max_value=5,
                interval_unit=TimeInterval.HOUR.value,
                interval_value=1
            )
            sqlite_backend_for_accounting.insert_usage_limit(global_limit)
            sqlite_backend_for_accounting.insert_usage_limit(model_limit)
            accounting_instance.quota_service.refresh_limits_cache() # Refresh cache after inserting limits

            # Make 5 requests that should be allowed by the model-specific limit
            for i in range(5):
                freezer.tick(delta=timedelta(seconds=1))
>               allowed, reason = accounting_instance.check_quota("gpt-4", "user1", "app1", 1000, 0.25)

tests/accounting/test_model_limits.py:54:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83df8310>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=100.0, interval_unit='minute', interval_value=1, model... 1, 1, 10, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 10, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1'
request_caller_name = 'app1', project_name_for_usage_sum = None
request_input_tokens = 1000, request_cost = 0.25, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
____________________ test_global_limit_overrides_user_limit ____________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe842d4430>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe842d6560>

    @freeze_time("2024-01-01 00:00:00", tz_offset=0)
    def test_global_limit_overrides_user_limit(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        global_limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=3,
            interval_unit=TimeInterval.SECOND_ROLLING.value,
            interval_value=10,
        )
        user_limit = UsageLimitDTO(
            scope=LimitScope.USER.value,
            username="user1",
            limit_type=LimitType.REQUESTS.value,
            max_value=10,
            interval_unit=TimeInterval.MINUTE.value,
            interval_value=1,
        )
        sqlite_backend_for_accounting.insert_usage_limit(global_limit)
        sqlite_backend_for_accounting.insert_usage_limit(user_limit)

        accounting_instance.quota_service.refresh_limits_cache()

        with freeze_time("2024-01-01 00:00:05", tz_offset=0) as freezer:
            for i in range(3):
                freezer.tick(delta=timedelta(seconds=1))
                accounting_instance.track_usage(
                    model="gpt-4",
                    username=f"u{i}",
                    caller_name="app",
                    prompt_tokens=1,
                    completion_tokens=1,
                    cost=0.0,
                    timestamp=datetime.now(timezone.utc),
                )

>           allowed, message = accounting_instance.check_quota(
                "gpt-4", "user1", "app", 1, 0.0
            )

tests/accounting/test_multi_dimensional_quota.py:62:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe8417c280>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=3.0, interval_unit='second_rolling', interval_value=10...4, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2024, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1', request_caller_name = 'app'
project_name_for_usage_sum = None, request_input_tokens = 1, request_cost = 0.0
request_completion_tokens = 0, limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
___________________ test_user_limit_triggered_before_global ____________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe83cbb550>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe83cbbfa0>

    @freeze_time("2024-01-01 00:00:00", tz_offset=0)
    def test_user_limit_triggered_before_global(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        global_limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=10,
            interval_unit=TimeInterval.MINUTE.value,
            interval_value=1,
        )
        user_limit = UsageLimitDTO(
            scope=LimitScope.USER.value,
            username="user1",
            limit_type=LimitType.REQUESTS.value,
            max_value=2,
            interval_unit=TimeInterval.MINUTE_ROLLING.value,
            interval_value=1,
        )
        sqlite_backend_for_accounting.insert_usage_limit(global_limit)
        sqlite_backend_for_accounting.insert_usage_limit(user_limit)

        accounting_instance.quota_service.refresh_limits_cache()

        with freeze_time("2024-01-01 00:00:30", tz_offset=0) as freezer:
            for _ in range(2):
                freezer.tick(delta=timedelta(seconds=1))
                accounting_instance.track_usage(
                    model="gpt-4",
                    username="user1",
                    caller_name="app",
                    prompt_tokens=1,
                    completion_tokens=1,
                    cost=0.0,
                    timestamp=datetime.now(timezone.utc),
                )
            for _ in range(5):
                freezer.tick(delta=timedelta(seconds=1))
                accounting_instance.track_usage(
                    model="gpt-4",
                    username="other",
                    caller_name="app",
                    prompt_tokens=1,
                    completion_tokens=1,
                    cost=0.0,
                    timestamp=datetime.now(timezone.utc),
                )

>           allowed, message = accounting_instance.check_quota(
                "gpt-4", "user1", "app", 1, 0.0
            )

tests/accounting/test_multi_dimensional_quota.py:117:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe842d5e40>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=10.0, interval_unit='minute', interval_value=1, model=...4, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2024, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1', request_caller_name = 'app'
project_name_for_usage_sum = None, request_input_tokens = 1, request_cost = 0.0
request_completion_tokens = 0, limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
________________ test_model_and_project_limits_first_triggered _________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe83df5de0>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe83df6200>

    @freeze_time("2024-01-01 00:10:00", tz_offset=0)
    def test_model_and_project_limits_first_triggered(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        project_limit = UsageLimitDTO(
            scope=LimitScope.PROJECT.value,
            project_name="projA",
            limit_type=LimitType.COST.value,
            max_value=5.0,
            interval_unit=TimeInterval.DAY.value,
            interval_value=1,
        )
        model_limit = UsageLimitDTO(
            scope=LimitScope.MODEL.value,
            model="gpt-4",
            limit_type=LimitType.INPUT_TOKENS.value,
            max_value=100,
            interval_unit=TimeInterval.MINUTE_ROLLING.value,
            interval_value=1,
        )
        sqlite_backend_for_accounting.insert_usage_limit(project_limit)
        sqlite_backend_for_accounting.insert_usage_limit(model_limit)

        accounting_instance.quota_service.refresh_limits_cache()

        accounting_instance.track_usage(
            model="gpt-4",
            username="user1",
            caller_name="app",
            prompt_tokens=10,
            completion_tokens=10,
            cost=5.0,
            project="projA",
            timestamp=datetime(2024, 1, 1, 0, 9, 0, tzinfo=timezone.utc),
        )
        for _ in range(3):
            accounting_instance.track_usage(
                model="gpt-4",
                username="user1",
                caller_name="app",
                prompt_tokens=20,
                completion_tokens=0,
                cost=0.0,
                project="projA",
                timestamp=datetime.now(timezone.utc),
            )

>       allowed, message = accounting_instance.check_quota(
            "gpt-4", "user1", "app", 50, 1.0, project_name="projA"
        )

tests/accounting/test_multi_dimensional_quota.py:171:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83d95bd0>
limits = [UsageLimitDTO(scope='PROJECT', limit_type='cost', max_value=5.0, interval_unit='day', interval_value=1, model=None, u... 1, 1, 0, 10, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2024, 1, 1, 0, 10, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1', request_caller_name = 'app'
project_name_for_usage_sum = 'projA', request_input_tokens = 50
request_cost = 1.0, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
________________________ test_denial_cache_ttl_behavior ________________________

    @freeze_time("2024-01-01 00:00:40", tz_offset=0)
    def test_denial_cache_ttl_behavior():
        from unittest.mock import MagicMock
        mock_backend = MagicMock(spec=BaseBackend)

        limit = UsageLimitDTO(
            scope=LimitScope.GLOBAL.value,
            limit_type=LimitType.REQUESTS.value,
            max_value=1,
            interval_unit=TimeInterval.MINUTE.value,
            interval_value=1,
        )
        mock_backend.get_usage_limits.return_value = [limit]
        mock_backend.get_accounting_entries_for_quota.return_value = 1.0

        quota_service = QuotaService(mock_backend)
        quota_service.refresh_limits_cache()

>       allowed, reason, retry_after = quota_service.check_quota_enhanced(
            model="gpt-4", username="u", caller_name="app", input_tokens=1, cost=0.0
        )

tests/accounting/test_multi_dimensional_quota.py:196:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83cb4b50>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=1, interval_unit='minute', interval_value=1, model=None, username=None, caller_name=None, project_name=None, id=None, created_at=None, updated_at=None)]
request_model = 'gpt-4', request_username = 'u', request_caller_name = 'app'
project_name_for_usage_sum = None, request_input_tokens = 1, request_cost = 0.0
request_completion_tokens = 0, limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
__________________________ test_multiple_limit_types ___________________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe83c733d0>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe83c72e60>

    def test_multiple_limit_types(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer:
            # Setting up a token-based limit directly on the backend using UsageLimitData
            token_limit = UsageLimitDTO(
                scope=LimitScope.USER.value,
                username="user2",
                limit_type=LimitType.INPUT_TOKENS.value,
                max_value=10000,
                interval_unit=TimeInterval.DAY.value,
                interval_value=1
            )
            sqlite_backend_for_accounting.insert_usage_limit(token_limit)

            # Setting up a cost-based limit directly on the backend using UsageLimitData
            cost_limit = UsageLimitDTO(
                scope=LimitScope.USER.value,
                username="user2",
                limit_type=LimitType.COST.value,
                max_value=50.00,
                interval_unit=TimeInterval.WEEK.value,
                interval_value=1
            )
            sqlite_backend_for_accounting.insert_usage_limit(cost_limit)


            # Refresh the cache in QuotaService after inserting all limits
            accounting_instance.quota_service.refresh_limits_cache()

            # Test token limit is enforced
            # Ensure a timestamp for the check, though not strictly needed if not tracking yet
            freezer.tick(delta=timedelta(seconds=1)) # Advance time for the token check
            # current_time_token_check = datetime.now(timezone.utc) # Not strictly needed as check_quota uses frozen time
>           allowed_tokens, message_tokens = accounting_instance.check_quota(
                "gpt-4", "user2", "app2", 15000, 0.0
                # project_name and completion_tokens can be omitted if not relevant to specific limits being tested
            )

tests/accounting/test_multiple_limit_types.py:61:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe842e70a0>
limits = [UsageLimitDTO(scope='USER', limit_type='input_tokens', max_value=10000.0, interval_unit='day', interval_value=1, mode...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user2'
request_caller_name = 'app2', project_name_for_usage_sum = None
request_input_tokens = 15000, request_cost = 0.0, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
_________________________ test_user_caller_combination _________________________

accounting_instance = <llm_accounting.LLMAccounting object at 0x7efe841126e0>
sqlite_backend_for_accounting = <llm_accounting.backends.sqlite.SQLiteBackend object at 0x7efe84111c60>

    def test_user_caller_combination(accounting_instance: LLMAccounting, sqlite_backend_for_accounting: SQLiteBackend):
        with freeze_time("2023-01-01 00:00:00", tz_offset=0) as freezer:
            # Setting up a caller-specific limit directly on the backend using UsageLimitData
            caller_limit = UsageLimitDTO(
                scope=LimitScope.CALLER.value,
                username="user1",
                caller_name="app1",
                limit_type=LimitType.REQUESTS.value,
                max_value=3,
                interval_unit=TimeInterval.DAY.value,
                interval_value=1
            )
            sqlite_backend_for_accounting.insert_usage_limit(caller_limit)
            accounting_instance.quota_service.refresh_limits_cache() # Refresh cache after inserting limits

            # Make 3 allowed requests for user1, app1
            for i in range(3):
                freezer.tick(delta=timedelta(seconds=1))
>               allowed, reason = accounting_instance.check_quota("gpt-3", "user1", "app1", 1000, 0.25)

tests/accounting/test_user_caller_limits.py:47:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe841bd570>
limits = [UsageLimitDTO(scope='CALLER', limit_type='requests', max_value=3.0, interval_unit='day', interval_value=1, model=None...3, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-3', request_username = 'user1'
request_caller_name = 'app1', project_name_for_usage_sum = None
request_input_tokens = 1000, request_cost = 0.25, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
___________________________ test_project_limit_cost ____________________________

accounting_for_quota = <llm_accounting.LLMAccounting object at 0x7efe83dd74c0>

    def test_project_limit_cost(accounting_for_quota: LLMAccounting):
        """Test cost limit scoped to a specific project."""
        project_a = "ProjectA"
        with freeze_time("2023-01-01 12:00:00", tz_offset=0) as freezer:
            accounting_for_quota.set_usage_limit(
                scope=LimitScope.PROJECT,
                limit_type=LimitType.COST,
                max_value=5.0,
                interval_unit=TimeInterval.DAY,
                interval_value=1,
                project_name=project_a
            )
            accounting_for_quota.quota_service.refresh_limits_cache()

            add_usage(accounting_for_quota, freezer, model="gpt-4", cost=2.0, input_tokens=10, project_name=project_a, count=2)
            # Debugging: Check if data is inserted
            print(f"Entries after first add_usage: {accounting_for_quota.tail(n=5)}")
>           allowed, _ = accounting_for_quota.check_quota(model="gpt-4", cost=1.0, input_tokens=10, project_name=project_a, username="user1", caller_name="app1")

tests/core/test_project_quota_service.py:56:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83dd7ee0>
limits = [UsageLimitDTO(scope='PROJECT', limit_type='cost', max_value=5.0, interval_unit='day', interval_value=1, model=None, u... 1, 1, 12, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1'
request_caller_name = 'app1', project_name_for_usage_sum = 'ProjectA'
request_input_tokens = 10, request_cost = 1.0, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
----------------------------- Captured stdout call -----------------------------
Entries after first add_usage: [UsageEntry(model='gpt-4', id=None, prompt_tokens=10, completion_tokens=0, total_tokens=0, local_prompt_tokens=0, local_completion_tokens=0, local_total_tokens=0, cost=2.0, execution_time=0.0, timestamp=FakeDatetime(2023, 1, 1, 12, 0, 0, 20000), caller_name='test_caller', username='test_user', project='ProjectA', cached_tokens=0, reasoning_tokens=0), UsageEntry(model='gpt-4', id=None, prompt_tokens=10, completion_tokens=0, total_tokens=0, local_prompt_tokens=0, local_completion_tokens=0, local_total_tokens=0, cost=2.0, execution_time=0.0, timestamp=FakeDatetime(2023, 1, 1, 12, 0, 0, 10000), caller_name='test_caller', username='test_user', project='ProjectA', cached_tokens=0, reasoning_tokens=0)]
_________________________ test_project_limit_requests __________________________

accounting_for_quota = <llm_accounting.LLMAccounting object at 0x7efe84129420>

    def test_project_limit_requests(accounting_for_quota: LLMAccounting):
        """Test request limit scoped to a specific project."""
        project_c = "ProjectC"
        with freeze_time("2023-01-01 12:00:00", tz_offset=0) as freezer:
            accounting_for_quota.set_usage_limit(
                scope=LimitScope.PROJECT,
                limit_type=LimitType.REQUESTS,
                max_value=2.0,
                interval_unit=TimeInterval.DAY,
                interval_value=1,
                project_name=project_c
            )
            accounting_for_quota.quota_service.refresh_limits_cache()

            add_usage(accounting_for_quota, freezer, model="claude-2", cost=0.1, input_tokens=5, project_name=project_c, count=1)
>           allowed, _ = accounting_for_quota.check_quota(model="claude-2", cost=0.1, input_tokens=5, project_name=project_c, username="user2", caller_name="app2")

tests/core/test_project_quota_service.py:88:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83c701f0>
limits = [UsageLimitDTO(scope='PROJECT', limit_type='requests', max_value=2.0, interval_unit='day', interval_value=1, model=Non... 1, 1, 12, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc))]
request_model = 'claude-2', request_username = 'user2'
request_caller_name = 'app2', project_name_for_usage_sum = 'ProjectC'
request_input_tokens = 5, request_cost = 0.1, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
__________________ test_project_limit_with_global_limit_cost ___________________

accounting_for_quota = <llm_accounting.LLMAccounting object at 0x7efe83660d60>

    def test_project_limit_with_global_limit_cost(accounting_for_quota: LLMAccounting):
        """Test interaction between a project-specific cost limit and a global cost limit."""
        project_d = "ProjectD"
        project_e = "ProjectE"
        with freeze_time("2023-01-01 12:00:00", tz_offset=0) as freezer:
            accounting_for_quota.set_usage_limit(LimitScope.GLOBAL, LimitType.COST, 10.0, TimeInterval.DAY, 1)
            accounting_for_quota.set_usage_limit(LimitScope.PROJECT, LimitType.COST, 5.0, TimeInterval.DAY, 1, project_name=project_d)
            accounting_for_quota.quota_service.refresh_limits_cache()

            add_usage(accounting_for_quota, freezer, model="gpt-4", cost=2.0, input_tokens=10, project_name=project_d, count=2)
>           allowed, _ = accounting_for_quota.check_quota(model="gpt-4", cost=1.0, input_tokens=10, project_name=project_d, username="user1", caller_name="app1")

tests/core/test_project_quota_service.py:109:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83660b20>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='cost', max_value=10.0, interval_unit='day', interval_value=1, model=None, u... 1, 1, 12, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1'
request_caller_name = 'app1', project_name_for_usage_sum = 'ProjectD'
request_input_tokens = 10, request_cost = 1.0, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
_____________________ test_project_limit_with_model_limit ______________________

accounting_for_quota = <llm_accounting.LLMAccounting object at 0x7efe8412a890>

    def test_project_limit_with_model_limit(accounting_for_quota: LLMAccounting):
        """Test interaction between project limit and model limit."""
        project_f = "ProjectF"
        project_g = "ProjectG"
        model_name = "special-model"
        with freeze_time("2023-01-01 12:00:00", tz_offset=0) as freezer:
            accounting_for_quota.set_usage_limit(LimitScope.MODEL, LimitType.REQUESTS, 3, TimeInterval.DAY, 1, model=model_name)
            accounting_for_quota.set_usage_limit(LimitScope.PROJECT, LimitType.REQUESTS, 2, TimeInterval.DAY, 1, model=model_name, project_name=project_f)
            accounting_for_quota.quota_service.refresh_limits_cache()

            add_usage(accounting_for_quota, freezer, model=model_name, cost=0.1, input_tokens=1, project_name=project_f)
>           allowed, _ = accounting_for_quota.check_quota(model=model_name, cost=0.1, input_tokens=1, project_name=project_f, username="u", caller_name="c")

tests/core/test_project_quota_service.py:140:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe8555aa40>
limits = [UsageLimitDTO(scope='MODEL', limit_type='requests', max_value=3.0, interval_unit='day', interval_value=1, model='spec... 1, 1, 12, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc))]
request_model = 'special-model', request_username = 'u'
request_caller_name = 'c', project_name_for_usage_sum = 'ProjectF'
request_input_tokens = 1, request_cost = 0.1, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
____________ test_project_limit_with_no_specific_project_in_request ____________

accounting_for_quota = <llm_accounting.LLMAccounting object at 0x7efe8353b130>

    def test_project_limit_with_no_specific_project_in_request(accounting_for_quota: LLMAccounting):
        """Test that a request with no project is not affected by a project-specific limit."""
        project_h = "ProjectH"
        with freeze_time("2023-01-01 12:00:00", tz_offset=0) as freezer:
            accounting_for_quota.set_usage_limit(
                scope=LimitScope.PROJECT,
                limit_type=LimitType.COST,
                max_value=1.0,
                interval_unit=TimeInterval.DAY,
                interval_value=1,
                project_name=project_h
            )
            accounting_for_quota.quota_service.refresh_limits_cache()
            allowed, _ = accounting_for_quota.check_quota(model="gpt-4", cost=2.0, input_tokens=10, project_name=None, username="user1", caller_name="app1")
            assert allowed, "Request with no project should not be affected by ProjectH's limit"

            add_usage(accounting_for_quota, freezer, model="gpt-4", cost=1.0, input_tokens=10, project_name=project_h)
>           allowed, _ = accounting_for_quota.check_quota(model="gpt-4", cost=0.1, input_tokens=1, project_name=project_h, username="user1", caller_name="app1")

tests/core/test_project_quota_service.py:172:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe8353ab90>
limits = [UsageLimitDTO(scope='PROJECT', limit_type='cost', max_value=1.0, interval_unit='day', interval_value=1, model=None, u... 1, 1, 12, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'user1'
request_caller_name = 'app1', project_name_for_usage_sum = 'ProjectH'
request_input_tokens = 1, request_cost = 0.1, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
_____________________ test_limit_message_for_project_scope _____________________

accounting_for_quota = <llm_accounting.LLMAccounting object at 0x7efe83c13b20>

    def test_limit_message_for_project_scope(accounting_for_quota: LLMAccounting):
        """Test the limit exhaustion message for project-scoped limits."""
        project_name = "DetailProject"
        model_name = "detailed-model"
        with freeze_time("2023-01-01 12:00:00", tz_offset=0) as freezer:
            accounting_for_quota.set_usage_limit(
                scope=LimitScope.PROJECT,
                limit_type=LimitType.REQUESTS,
                max_value=1,
                interval_unit=TimeInterval.DAY,
                interval_value=1,
                project_name=project_name,
                model=model_name
            )
            accounting_for_quota.quota_service.refresh_limits_cache()
            add_usage(accounting_for_quota, freezer, model=model_name, cost=0.1, input_tokens=1, project_name=project_name)
>           allowed, message = accounting_for_quota.check_quota(model=model_name, cost=0.1, input_tokens=1, project_name=project_name, username="u", caller_name="c")

tests/core/test_project_quota_service.py:194:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/__init__.py:158: in check_quota
    return self.quota_service.check_quota(
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83c13670>
limits = [UsageLimitDTO(scope='PROJECT', limit_type='requests', max_value=1.0, interval_unit='day', interval_value=1, model='de... 1, 1, 12, 0, tzinfo=datetime.timezone.utc), updated_at=FakeDatetime(2023, 1, 1, 12, 0, tzinfo=datetime.timezone.utc))]
request_model = 'detailed-model', request_username = 'u'
request_caller_name = 'c', project_name_for_usage_sum = 'DetailProject'
request_input_tokens = 1, request_cost = 0.1, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
---------------------------- Captured stderr setup -----------------------------
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> 82f27c891782, initial_tables
INFO  [alembic.runtime.migration] Running upgrade 82f27c891782 -> ba9718840e75, add_notes_to_accounting_entry
____________________ test_check_quota_allowed_single_limit _____________________

mock_backend = <MagicMock spec='BaseBackend' id='139631590904672'>

    def test_check_quota_allowed_single_limit(mock_backend: MagicMock):
        """Test check_quota when usage is within a single configured limit."""
        now = datetime.now(timezone.utc)
        user_cost_limit = UsageLimitDTO(
            id=1, scope=LimitScope.USER.value, limit_type=LimitType.COST.value,
            max_value=10.0, interval_unit=TimeInterval.MONTH.value, interval_value=1,
            username="test_user", created_at=now, updated_at=now
        )
        mock_backend.get_usage_limits.return_value = [user_cost_limit]
        quota_service = QuotaService(mock_backend)

        mock_backend.get_accounting_entries_for_quota.return_value = 5.0

>       is_allowed, reason = quota_service.check_quota(
            model="gpt-4", username="test_user", caller_name="test_caller",
            input_tokens=100, cost=0.01
        )

tests/core/test_quota_service.py:46:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe836020e0>
limits = [UsageLimitDTO(scope='USER', limit_type='cost', max_value=10.0, interval_unit='monthly', interval_value=1, model=None,...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 35, 984705, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'test_user'
request_caller_name = 'test_caller', project_name_for_usage_sum = None
request_input_tokens = 100, request_cost = 0.01, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
_____________________ test_check_quota_denied_single_limit _____________________

mock_backend = <MagicMock spec='BaseBackend' id='139631598089936'>

    def test_check_quota_denied_single_limit(mock_backend: MagicMock):
        """Test check_quota when usage exceeds a single configured limit."""
        now = datetime.now(timezone.utc)
        user_cost_limit = UsageLimitDTO(
            id=1, scope=LimitScope.USER.value, limit_type=LimitType.COST.value,
            max_value=10.0, interval_unit=TimeInterval.MONTH.value, interval_value=1,
            username="test_user", created_at=now, updated_at=now
        )
        mock_backend.get_usage_limits.return_value = [user_cost_limit]
        # Instantiate QuotaService AFTER setting the mock return value.
        # The first call to check_quota will load the cache if it's None.
        quota_service = QuotaService(mock_backend)

        mock_backend.get_accounting_entries_for_quota.return_value = 9.99

>       is_allowed, reason = quota_service.check_quota(
            model="gpt-4", username="test_user", caller_name="test_caller",
            input_tokens=0, cost=0.02
        )

tests/core/test_quota_service.py:76:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83653940>
limits = [UsageLimitDTO(scope='USER', limit_type='cost', max_value=10.0, interval_unit='monthly', interval_value=1, model=None,...nfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 36, 45402, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'test_user'
request_caller_name = 'test_caller', project_name_for_usage_sum = None
request_input_tokens = 0, request_cost = 0.02, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
________________ test_check_quota_multiple_limits_one_exceeded _________________

mock_backend = <MagicMock spec='BaseBackend' id='139631605527360'>

    def test_check_quota_multiple_limits_one_exceeded(mock_backend: MagicMock):
        """Test check_quota with multiple limits, where one is exceeded."""
        now = datetime.now(timezone.utc)
        cost_limit_user = UsageLimitDTO(
            id=1, scope=LimitScope.USER.value, limit_type=LimitType.COST.value,
            max_value=10.0, interval_unit=TimeInterval.MONTH.value, interval_value=1,
            username="test_user", created_at=now, updated_at=now
        )
        request_limit_user = UsageLimitDTO(
            id=2, scope=LimitScope.USER.value, limit_type=LimitType.REQUESTS.value,
            max_value=100.0, interval_unit=TimeInterval.DAY.value, interval_value=1,
            username="test_user", created_at=now, updated_at=now
        )
        mock_backend.get_usage_limits.return_value = [cost_limit_user, request_limit_user]
        quota_service = QuotaService(mock_backend)

        def get_accounting_side_effect(start_time, end_time, limit_type, interval_unit, model, username, caller_name, project_name, filter_project_null):
            if limit_type == LimitType.COST and username == "test_user":
                return 5.0
            elif limit_type == LimitType.REQUESTS and username == "test_user":
                return 100.0
            return 0.0

        mock_backend.get_accounting_entries_for_quota.side_effect = get_accounting_side_effect

>       is_allowed, reason = quota_service.check_quota(
            model="gpt-4", username="test_user", caller_name="test_caller",
            input_tokens=10, cost=0.01
        )

tests/core/test_quota_service.py:115:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe841ada50>
limits = [UsageLimitDTO(scope='USER', limit_type='cost', max_value=10.0, interval_unit='monthly', interval_value=1, model=None,...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 36, 105893, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'test_user'
request_caller_name = 'test_caller', project_name_for_usage_sum = None
request_input_tokens = 10, request_cost = 0.01, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
__________________ test_check_quota_different_scopes_in_cache __________________

mock_backend = <MagicMock spec='BaseBackend' id='139631597940320'>

    def test_check_quota_different_scopes_in_cache(mock_backend: MagicMock):
        """Test that QuotaService correctly filters from cache for different scopes."""
        now = datetime.now(timezone.utc)
        global_req_limit = UsageLimitDTO(id=1, scope=LimitScope.GLOBAL.value, limit_type=LimitType.REQUESTS.value, max_value=5, interval_unit=TimeInterval.MINUTE.value, interval_value=1)
        user_cost_limit = UsageLimitDTO(id=2, scope=LimitScope.USER.value, username="test_user", limit_type=LimitType.COST.value, max_value=10, interval_unit=TimeInterval.DAY.value, interval_value=1)
        model_token_limit = UsageLimitDTO(id=3, scope=LimitScope.MODEL.value, model="gpt-4", limit_type=LimitType.INPUT_TOKENS.value, max_value=1000, interval_unit=TimeInterval.HOUR.value, interval_value=1)

        mock_backend.get_usage_limits.return_value = [global_req_limit, user_cost_limit, model_token_limit]
        quota_service = QuotaService(mock_backend)

        mock_backend.get_accounting_entries_for_quota.return_value = 5.0

>       is_allowed, reason = quota_service.check_quota(
            model="gpt-4", username="test_user", caller_name="super_caller",
            input_tokens=1, cost=0.001
        )

tests/core/test_quota_service.py:141:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83b51ed0>
limits = [UsageLimitDTO(scope='GLOBAL', limit_type='requests', max_value=5, interval_unit='minute', interval_value=1, model=Non...al_value=1, model='gpt-4', username=None, caller_name=None, project_name=None, id=3, created_at=None, updated_at=None)]
request_model = 'gpt-4', request_username = 'test_user'
request_caller_name = 'super_caller', project_name_for_usage_sum = None
request_input_tokens = 1, request_cost = 0.001, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
________________________ test_check_quota_token_limits _________________________

mock_backend = <MagicMock spec='BaseBackend' id='139631604159040'>

    def test_check_quota_token_limits(mock_backend: MagicMock):
        """Test check_quota for input token limits from cache."""
        now = datetime.now(timezone.utc)
        model_token_limit = UsageLimitDTO(
            id=1, scope=LimitScope.MODEL.value, limit_type=LimitType.INPUT_TOKENS.value,
            max_value=1000.0, interval_unit=TimeInterval.HOUR.value, interval_value=1,
            model="text-davinci-003", created_at=now, updated_at=now
        )
        mock_backend.get_usage_limits.return_value = [model_token_limit]
        quota_service = QuotaService(mock_backend)

        mock_backend.get_accounting_entries_for_quota.return_value = 950.0

>       is_allowed, reason = quota_service.check_quota(
            model="text-davinci-003", username="any_user", caller_name="any_caller",
            input_tokens=50, cost=0.0
        )

tests/core/test_quota_service.py:169:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:41: in check_quota
    allowed, reason, _ = self.check_quota_enhanced(
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83dfb010>
limits = [UsageLimitDTO(scope='MODEL', limit_type='input_tokens', max_value=1000.0, interval_unit='hour', interval_value=1, mod...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 36, 226253, tzinfo=datetime.timezone.utc))]
request_model = 'text-davinci-003', request_username = 'any_user'
request_caller_name = 'any_caller', project_name_for_usage_sum = None
request_input_tokens = 50, request_cost = 0.0, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
________________ test_check_quota_enhanced_allowed_single_limit ________________

mock_backend = <MagicMock spec='BaseBackend' id='139631589867872'>

    def test_check_quota_enhanced_allowed_single_limit(mock_backend: MagicMock):
        """Test check_quota_enhanced when usage is within a single configured limit."""
        now = datetime.now(timezone.utc)
        user_cost_limit = UsageLimitDTO(
            id=1, scope=LimitScope.USER.value, limit_type=LimitType.COST.value,
            max_value=10.0, interval_unit=TimeInterval.MONTH.value, interval_value=1,
            username="test_user", created_at=now, updated_at=now
        )
        mock_backend.get_usage_limits.return_value = [user_cost_limit]
        quota_service = QuotaService(mock_backend)

        mock_backend.get_accounting_entries_for_quota.return_value = 5.0

>       is_allowed, reason, retry_after = quota_service.check_quota_enhanced(
            model="gpt-4", username="test_user", caller_name="test_caller",
            input_tokens=100, cost=0.01
        )

tests/core/test_quota_service.py:304:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/llm_accounting/services/quota_service.py:95: in check_quota_enhanced
    allowed, reason, reset_timestamp = self.limit_evaluator._evaluate_limits_enhanced(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <llm_accounting.services.quota_service_parts._limit_evaluator.QuotaServiceLimitEvaluator object at 0x7efe83541c60>
limits = [UsageLimitDTO(scope='USER', limit_type='cost', max_value=10.0, interval_unit='monthly', interval_value=1, model=None,...fo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 6, 8, 17, 11, 36, 375325, tzinfo=datetime.timezone.utc))]
request_model = 'gpt-4', request_username = 'test_user'
request_caller_name = 'test_caller', project_name_for_usage_sum = None
request_input_tokens = 100, request_cost = 0.01, request_completion_tokens = 0
limit_scope_for_message = None

    def _evaluate_limits_enhanced(
        self,
        limits: List[UsageLimitDTO],
        request_model: Optional[str],
        request_username: Optional[str],
        request_caller_name: Optional[str],
        project_name_for_usage_sum: Optional[str],
        request_input_tokens: int,
        request_cost: float,
        request_completion_tokens: int,
        limit_scope_for_message: Optional[str] = None,
    ) -> Tuple[bool, Optional[str], Optional[datetime]]: # Changed return type
        now = datetime.now(timezone.utc) # Keep timezone-aware
        for limit in limits:
            if self._should_skip_limit(limit, request_model, request_username, request_caller_name, project_name_for_usage_sum):
                continue

            interval_unit_enum = TimeInterval(limit.interval_unit) # Get enum member
            period_start_time = self._get_period_start(now, interval_unit_enum, limit.interval_value)

            reset_timestamp = self._calculate_reset_timestamp(period_start_time, limit, interval_unit_enum)

            final_usage_query_model: Optional[str] = None
            final_usage_query_username: Optional[str] = None
            final_usage_query_caller_name: Optional[str] = None
            final_usage_query_project_name: Optional[str] = None
            final_usage_query_filter_project_null: Optional[bool] = None

>           if limit_scope_enum == LimitScope.GLOBAL:
E           NameError: name 'limit_scope_enum' is not defined

src/llm_accounting/services/quota_service_parts/_limit_evaluator.py:288: NameError
=============================== warnings summary ===============================
../usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py:1441
  /usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py:1441: PytestConfigWarning: Unknown config option: asyncio_default_fixture_loop_scope

    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/accounting/rolling_limits_tests/test_day_rolling_limits.py::TestDayRollingLimits::test_day_rolling_limit_output_tokens
FAILED tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py::TestHourRollingLimits::test_hour_rolling_boundary_just_inside
FAILED tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py::TestHourRollingLimits::test_hour_rolling_boundary_just_outside
FAILED tests/accounting/rolling_limits_tests/test_hour_rolling_limits.py::TestHourRollingLimits::test_no_usage_rolling_limit
FAILED tests/accounting/rolling_limits_tests/test_minute_rolling_limits.py::TestMinuteRollingLimits::test_minute_rolling_limit_input_tokens
FAILED tests/accounting/rolling_limits_tests/test_mixed_rolling_limits.py::TestMixedRollingLimits::test_mixed_fixed_and_rolling_limits_rolling_exceeded
FAILED tests/accounting/rolling_limits_tests/test_mixed_rolling_limits.py::TestMixedRollingLimits::test_multiple_rolling_limits_one_exceeded
FAILED tests/accounting/rolling_limits_tests/test_month_rolling_limits.py::TestMonthRollingLimits::test_month_rolling_limit_requests
FAILED tests/accounting/rolling_limits_tests/test_second_rolling_limits.py::TestSecondRollingLimits::test_basic_second_rolling_limit_exceed_limit
FAILED tests/accounting/rolling_limits_tests/test_second_rolling_limits.py::TestSecondRollingLimits::test_basic_second_rolling_limit_within_limit
FAILED tests/accounting/rolling_limits_tests/test_second_rolling_limits.py::TestSecondRollingLimits::test_second_rolling_limit_usage_outside_window
FAILED tests/accounting/rolling_limits_tests/test_week_rolling_limits.py::TestWeekRollingLimits::test_week_rolling_limit_cost
FAILED tests/accounting/test_account_model_limits.py::test_account_model_requests_per_minute
FAILED tests/accounting/test_account_model_limits.py::test_account_model_requests_per_day
FAILED tests/accounting/test_account_model_limits.py::test_account_model_completion_tokens_per_minute
FAILED tests/accounting/test_account_model_limits.py::test_account_model_completion_tokens_per_day
FAILED tests/accounting/test_account_model_limits.py::test_account_total_requests_per_minute
FAILED tests/accounting/test_comprehensive_limits.py::test_comprehensive_limit_scenarios
FAILED tests/accounting/test_global_limits.py::test_global_limit - NameError:...
FAILED tests/accounting/test_model_limits.py::test_model_limit_priority - Nam...
FAILED tests/accounting/test_multi_dimensional_quota.py::test_global_limit_overrides_user_limit
FAILED tests/accounting/test_multi_dimensional_quota.py::test_user_limit_triggered_before_global
FAILED tests/accounting/test_multi_dimensional_quota.py::test_model_and_project_limits_first_triggered
FAILED tests/accounting/test_multi_dimensional_quota.py::test_denial_cache_ttl_behavior
FAILED tests/accounting/test_multiple_limit_types.py::test_multiple_limit_types
FAILED tests/accounting/test_user_caller_limits.py::test_user_caller_combination
FAILED tests/core/test_project_quota_service.py::test_project_limit_cost - Na...
FAILED tests/core/test_project_quota_service.py::test_project_limit_requests
FAILED tests/core/test_project_quota_service.py::test_project_limit_with_global_limit_cost
FAILED tests/core/test_project_quota_service.py::test_project_limit_with_model_limit
FAILED tests/core/test_project_quota_service.py::test_project_limit_with_no_specific_project_in_request
FAILED tests/core/test_project_quota_service.py::test_limit_message_for_project_scope
FAILED tests/core/test_quota_service.py::test_check_quota_allowed_single_limit
FAILED tests/core/test_quota_service.py::test_check_quota_denied_single_limit
FAILED tests/core/test_quota_service.py::test_check_quota_multiple_limits_one_exceeded
FAILED tests/core/test_quota_service.py::test_check_quota_different_scopes_in_cache
FAILED tests/core/test_quota_service.py::test_check_quota_token_limits - Name...
FAILED tests/core/test_quota_service.py::test_check_quota_enhanced_allowed_single_limit
===== 38 failed, 163 passed, 24 skipped, 1 deselected, 1 warning in 10.07s =====
